{
 "metadata": {
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.1-final"
  },
  "orig_nbformat": 2,
  "kernelspec": {
   "name": "python381jvsc74a57bd0808c0b65fb29d89f35c9ec8e00426afb986d0b65f026dc2bfd8b25d992fc8a8f",
   "display_name": "Python 3.8.1 32-bit"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2,
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 205,
   "metadata": {},
   "outputs": [],
   "source": [
    "Identifier_and_Name = {\n",
    "    \"Au-PeEL\": \"Ebook Library\",\n",
    "    \"CaONFJC\": \"MyiLibrary\",\n",
    "    \"CaPaEBR\": \"Ebrary\",\n",
    "    \"DE-He213\": \"Springer-Verlag\",\n",
    "    \"MiAaPQ\": \"ProQuest\",\n",
    "    \"NhCcYBP\": \"YBP\",\n",
    "    \"OCoLC\": \"OCLC\",\n",
    "    \"SFPDA_MiAaPQ\": \"ProQuest\",\n",
    "    \"YBPUID\": \"YBP ID\",\n",
    "    \"MIL\": \"MyiLibrary\",\n",
    "    \"EBR\": \"Ebrary\",\n",
    "    \"EBL\": \"Ebook Library\",\n",
    "    \"EBC\": \"Ebook Central\",\n",
    "    \"CaBNVSL\": \"SIAM\",\n",
    "    \"CaBNvSL\": \"SIAM\",\n",
    "    \"DcWaAPA\": \"APA\",\n",
    "    \"DNLM\": \"US Med Library\",\n",
    "    \"FR-PaOEC\": \"OECD\",\n",
    "    \"IN-ChSCO\": \"Scope e-Knowedge Center\",\n",
    "    \"MiFhGG\": \"Gale\",\n",
    "    \"StDuBDS\": \"Bibliographic Data Services\",\n",
    "    \"UtOrBLW\": \"Backstage Library Works\",\n",
    "    \"VaAlASP\": \"Alexander Street Press\",\n",
    "    \"EBS\": \"EBSCO\",\n",
    "    \"FANhCcYBP\": \"YBP (FA)\",\n",
    "    \"UK-OxUP\": \"Oxford UP\",\n",
    "    \"no label\": \"Unlabeled\",\n",
    "}"
   ]
  },
  {
   "source": [
    "> Start by loading Alpeh Sequential text file into OpenRefine with column widths 10,6,2\n",
    "\n",
    "Put the unique name of the OpenRefine project for the BIB records in the variable `BIB_Project_Name` and run the cell"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 158,
   "metadata": {},
   "outputs": [],
   "source": [
    "BIB_Project_Name = \"oso_bib_3 8 2021 txt\""
   ]
  },
  {
   "source": [
    "# Organize BIB Record\n",
    "\n",
    "## Organize MARC Fields and Subfields\n",
    "Copy Organize_Alpeh_Sequential_for_BIB.json and paste into OpenRefine"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "source": [
    "## Pivot Subfields into Columns\n",
    "Use a filter on \"No Field Number\" to select the following subfields, invert, then remove all matching rows:\n",
    "\n",
    "- 020$a\n",
    "- 020$q\n",
    "- 020$z\n",
    "- 024$2\n",
    "- 024$a\n",
    "- 035$a\n",
    "- 245$a\n",
    "- 245$b\n",
    "- 245$c\n",
    "- 245$n\n",
    "- 250$a\n",
    "- 264$b\n",
    "- 264$c\n",
    "- 710$a\n",
    "- 710$e\n",
    "- 776$i\n",
    "- 776$z\n",
    "- 856$3\n",
    "- 856$u\n",
    "- 856$z\n",
    "- 897$a\n",
    "- 897$e\n",
    "\n",
    "Open a text filter for \"Fields,\" click on the number of choices to get the facet choices as TSV, paste into variable \"Columns\" below, and run cell"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 159,
   "metadata": {},
   "outputs": [],
   "source": [
    "Columns = \"\"\"\n",
    "020$a\t1782\n",
    "020$q\t1\n",
    "035$a\t3484\n",
    "245$a\t3704\n",
    "245$b\t2318\n",
    "245$c\t3667\n",
    "245$n\t111\n",
    "250$a\t623\n",
    "264$b\t3637\n",
    "264$c\t3635\n",
    "710$a\t155\n",
    "710$e\t5\n",
    "776$i\t3534\n",
    "776$z\t3766\n",
    "856$3\t3177\n",
    "856$u\t3698\n",
    "856$z\t2072\n",
    "897$a\t151\n",
    "897$e\t151\n",
    "Field #1 020$a\t1637\n",
    "Field #1 020$q\t121\n",
    "Field #1 035$a\t220\n",
    "Field #1 250$a\t1\n",
    "Field #1 264$b\t69\n",
    "Field #1 264$c\t69\n",
    "Field #1 710$a\t2\n",
    "Field #1 776$i\t26\n",
    "Field #1 776$z\t22\n",
    "Field #1 856$3\t2\n",
    "Field #1 856$u\t5\n",
    "Field #1 856$z\t2\n",
    "Field #1 897$a\t2\n",
    "Field #1 897$e\t2\n",
    "Field #10 020$z\t1\n",
    "Field #2 020$a\t1636\n",
    "Field #2 020$q\t121\n",
    "Field #2 020$z\t1\n",
    "Field #2 035$a\t220\n",
    "Field #2 250$a\t1\n",
    "Field #2 264$b\t1\n",
    "Field #2 264$c\t69\n",
    "Field #2 710$a\t2\n",
    "Field #2 776$i\t1\n",
    "Field #2 776$z\t50\n",
    "Field #2 856$3\t1\n",
    "Field #2 856$u\t3\n",
    "Field #2 856$z\t1\n",
    "Field #3 020$a\t96\n",
    "Field #3 020$q\t95\n",
    "Field #3 020$z\t128\n",
    "Field #3 035$a\t214\n",
    "Field #3 776$z\t4\n",
    "Field #4 020$a\t94\n",
    "Field #4 020$q\t88\n",
    "Field #4 020$z\t121\n",
    "Field #5 020$a\t37\n",
    "Field #5 020$q\t58\n",
    "Field #5 020$z\t75\n",
    "Field #6 020$a\t37\n",
    "Field #6 020$q\t41\n",
    "Field #6 020$z\t57\n",
    "Field #7 020$a\t3\n",
    "Field #7 020$q\t41\n",
    "Field #7 020$z\t38\n",
    "Field #8 020$a\t2\n",
    "Field #8 020$q\t11\n",
    "Field #8 020$z\t16\n",
    "Field #9 020$q\t2\n",
    "Field #9 020$z\t3\n",
    "\"\"\""
   ]
  },
  {
   "source": [
    "**Indicator columns deleted at this point--unsure how to handle/how or if to preserve beyond this point**\n",
    "\n",
    "Copy Pivot_Fields_and_Values.json and paste into OpenRefine"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 160,
   "metadata": {},
   "outputs": [],
   "source": [
    "Columns = Columns.split(\"\\n\")[1:-1] # The splice removes elements created by having the opening and closing quotes on their own lines\n",
    "Column_Names = []\n",
    "for Column in Columns:\n",
    "    Column = Column.rstrip(\"1234567890\")\n",
    "    Column = Column.rstrip(\"\\t\")\n",
    "    Column_Names.append(Column)\n",
    "\n",
    "with open('JSON_Output.txt', 'w') as For_OpenRefine:\n",
    "    For_OpenRefine.write(\"[\")\n",
    "    for Column in Column_Names:\n",
    "        Template_String = f\"\"\"\n",
    "            {{\n",
    "                \"op\": \"core/text-transform\",\n",
    "                \"engineConfig\": {{\n",
    "                \"facets\": [],\n",
    "                \"mode\": \"record-based\"\n",
    "                }},\n",
    "                \"columnName\": \"{Column}\",\n",
    "                \"expression\": \"grel:row.record.cells[\\\\\"{Column}\\\\\"].value[0]\",\n",
    "                \"onError\": \"keep-original\",\n",
    "                \"repeat\": false,\n",
    "                \"repeatCount\": 10,\n",
    "                \"description\": \"Fill up and down values in ``{Column}``\"\n",
    "            }},\n",
    "            {{\n",
    "                \"op\": \"core/blank-down\",\n",
    "                \"engineConfig\": {{\n",
    "                \"facets\": [],\n",
    "                \"mode\": \"record-based\"\n",
    "                }},\n",
    "                \"columnName\": \"{Column}\",\n",
    "                \"description\": \"Blank down cells in column ``{Column}``\"\n",
    "            }},\n",
    "        \"\"\"\n",
    "        For_OpenRefine.write(Template_String)\n",
    "    For_OpenRefine.write(\"]\")"
   ]
  },
  {
   "source": [
    "Run all cells, then copy JSON_Output.txt and paste into OpenRefine\n",
    "\n",
    "Copy Remove_Blank_Rows_After_Pivot.json and paste into OpenRefine"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 161,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "\n      {\n    \"op\": \"core/column-reorder\",\n    \"columnNames\": [\n      \"SYS Number\",\n      \"Count\",\n      \"020$a\",\n\"Field #1 020$a\",\n\"Field #2 020$a\",\n\"Field #3 020$a\",\n\"Field #4 020$a\",\n\"Field #5 020$a\",\n\"Field #6 020$a\",\n\"Field #7 020$a\",\n\"Field #8 020$a\",\n\"Field #2 020$z\",\n\"Field #3 020$z\",\n\"Field #4 020$z\",\n\"Field #5 020$z\",\n\"Field #6 020$z\",\n\"Field #7 020$z\",\n\"Field #8 020$z\",\n\"Field #9 020$z\",\n\"Field #10 020$z\",\n\"776$z\",\n\"Field #1 776$z\",\n\"Field #2 776$z\",\n\"Field #3 776$z\",\n\"020$q\",\n\"Field #1 020$q\",\n\"Field #2 020$q\",\n\"Field #3 020$q\",\n\"Field #4 020$q\",\n\"Field #5 020$q\",\n\"Field #6 020$q\",\n\"Field #7 020$q\",\n\"Field #8 020$q\",\n\"Field #9 020$q\",\n\"776$i\",\n\"Field #1 776$i\",\n\"Field #2 776$i\",\n\"035$a\",\n\"Field #1 035$a\",\n\"Field #2 035$a\",\n\"Field #3 035$a\",\n\"710$a\",\n\"Field #1 710$a\",\n\"Field #2 710$a\",\n\"710$e\",\n\"897$a\",\n\"Field #1 897$a\",\n\"897$e\",\n\"Field #1 897$e\",\n\"856$u\",\n\"Field #1 856$u\",\n\"Field #2 856$u\",\n\"856$z\",\n\"Field #1 856$z\",\n\"Field #2 856$z\",\n\"856$3\",\n\"Field #1 856$3\",\n\"Field #2 856$3\",\n\"264$c\",\n\"Field #1 264$c\",\n\"Field #2 264$c\",\n\"264$b\",\n\"Field #1 264$b\",\n\"Field #2 264$b\",\n\"245$c\",\n\"250$a\",\n\"Field #1 250$a\",\n\"Field #2 250$a\",\n\"245$n\",\n\"245$b\",\n\"245$a\"\n    ],\n    \"description\": \"Reorder columns\"\n  }\n\n"
     ]
    }
   ],
   "source": [
    "\n",
    "def Column_Order_as_Letter(MARC_Tag):\n",
    "    if MARC_Tag == \"020$a\":\n",
    "        return \"A\"\n",
    "    elif MARC_Tag == \"020$z\":\n",
    "        return \"B\"\n",
    "    elif MARC_Tag == \"776$z\":\n",
    "        return \"C\"\n",
    "    elif MARC_Tag == \"020$q\":\n",
    "        return \"D\"\n",
    "    elif MARC_Tag == \"776$i\":\n",
    "        return \"E\"\n",
    "    elif MARC_Tag == \"024$a\":\n",
    "        return \"F\"\n",
    "    elif MARC_Tag == \"024$2\":\n",
    "        return \"G\"\n",
    "    elif MARC_Tag == \"035$a\":\n",
    "        return \"H\"\n",
    "    elif MARC_Tag == \"710$a\":\n",
    "        return \"I\"\n",
    "    elif MARC_Tag == \"710$e\":\n",
    "        return \"J\"\n",
    "    elif MARC_Tag == \"897$a\":\n",
    "        return \"K\"\n",
    "    elif MARC_Tag == \"897$e\":\n",
    "        return \"L\"\n",
    "    elif MARC_Tag == \"856$u\":\n",
    "        return \"M\"\n",
    "    elif MARC_Tag == \"856$z\":\n",
    "        return \"N\"\n",
    "    elif MARC_Tag == \"856$3\":\n",
    "        return \"O\"\n",
    "    elif MARC_Tag == \"264$c\":\n",
    "        return \"P\"\n",
    "    elif MARC_Tag == \"264$b\":\n",
    "        return \"Q\"\n",
    "    elif MARC_Tag == \"245$c\":\n",
    "        return \"R\"\n",
    "    elif MARC_Tag == \"250$a\":\n",
    "        return \"S\"\n",
    "    elif MARC_Tag == \"245$n\":\n",
    "        return \"T\"\n",
    "    elif MARC_Tag == \"245$b\":\n",
    "        return \"U\"\n",
    "    elif MARC_Tag == \"245$a\":\n",
    "        return \"V\"\n",
    "    # No \"else\" statement because if there's a problem here, it will require manual intervention\n",
    "\n",
    "Column_Order = {\n",
    "    \"A\": {},\n",
    "    \"B\": {},\n",
    "    \"C\": {},\n",
    "    \"D\": {},\n",
    "    \"E\": {},\n",
    "    \"F\": {},\n",
    "    \"G\": {},\n",
    "    \"H\": {},\n",
    "    \"I\": {},\n",
    "    \"J\": {},\n",
    "    \"K\": {},\n",
    "    \"L\": {},\n",
    "    \"M\": {},\n",
    "    \"N\": {},\n",
    "    \"O\": {},\n",
    "    \"P\": {},\n",
    "    \"Q\": {},\n",
    "    \"R\": {},\n",
    "    \"S\": {},\n",
    "    \"T\": {},\n",
    "    \"U\": {},\n",
    "    \"V\": {},\n",
    "}\n",
    "\n",
    "# Create nested dictionary for ordering columns\n",
    "for Column in Column_Names:\n",
    "    if \" \" in Column: # Has field number\n",
    "        Field_Number = int(Column.split(\" \")[1][1:])\n",
    "        Ordering_Letter = Column_Order_as_Letter(Column.split(\" \")[2])\n",
    "        Column_Order[Ordering_Letter][Field_Number] = Column\n",
    "    else:\n",
    "        Ordering_Letter = Column_Order_as_Letter(Column)\n",
    "        Column_Order[Ordering_Letter][0] = Column\n",
    "\n",
    "# Ensure that all first column in pivots exist\n",
    "if not Column_Order[\"Q\"].get(0): # If there's no column that's just \"264$b\"\n",
    "    Column_Order[\"Q\"][0] = \"264$b\"\n",
    "if not Column_Order[\"P\"].get(0): # If there's no column that's jsut \"264$c\"\n",
    "    Column_Order[\"p\"][0] = \"264$c\"\n",
    "if not Column_Order[\"O\"].get(0): # If there's no column that's just \"856$u\"\n",
    "    Column_Order[\"O\"][0] = \"856$u\"\n",
    "if not Column_Order[\"A\"].get(0): # If there's no column that's just \"020$a\"\n",
    "    Column_Order[\"A\"][0] = \"020$a\"\n",
    "\n",
    "# Sort by field order within tags\n",
    "for key, value in Column_Order.items():\n",
    "    value = dict(sorted(value.items()))\n",
    "    Column_Order[key] = value\n",
    "\n",
    "# Create list of column values in order and surrounded by double quotes\n",
    "Column_Order_Values = []\n",
    "for Outer_Value in Column_Order.values():\n",
    "    for Inner_Value in Outer_Value.values():\n",
    "        Column_Order_Values.append('\"' + Inner_Value + '\"')\n",
    "\n",
    "# Create reordering step JSON\n",
    "Reordering_String = \",\\n\".join(Column_Order_Values)\n",
    "Template_String = f\"\"\"\n",
    "      {{\n",
    "    \"op\": \"core/column-reorder\",\n",
    "    \"columnNames\": [\n",
    "      \"SYS Number\",\n",
    "      \"Count\",\n",
    "      {Reordering_String}\n",
    "    ],\n",
    "    \"description\": \"Reorder columns\"\n",
    "  }}\n",
    "\"\"\"\n",
    "print(Template_String)\n",
    "\n",
    "        \n"
   ]
  },
  {
   "source": [
    "Run all the cells, copy the JSON that appears above, and paste it into OpenRefine\n",
    "\n",
    "Copy Organize_Rarely_Duplicated_Fields.json and paste into OpenRefine\n",
    "\n",
    "## Organize Publisher and Pub Date Fields\n",
    "\n",
    "**PUBLISHER DUPLICATE FIELDS RELATED TO DUPLICATION OF INFORMATION NOT NEEDED, SO PIVOT LEFT NO RECORDS WITH MULTIPLE ROWS; WHEN THAT DOES HAPPEN, JSON WILL NEED TO BE ADJUSTED**\n",
    "\n",
    "**PUBLISHER NOT PRESENT AT END; INVESTIGATE ISSUE**\n",
    "\n",
    "Copy Organize_Publisher_Fields.json and paste into OpenRefine\n",
    "\n",
    "**PUB DATE DUPLICATE FIELDS IDENTFIED BY FILTERING FOR RECORDS WHERE \"SYS NUMBER\" HAD BLANK CELLS; FIRAT CASE HAD SAME DATE TWICE, SO SECOND DATE WSN'T PRESERVED--NEED TO FIGURE OUT STRATEGY FOR IF WE WANT TO PRESERVE BOTH DATES**\n",
    "\n",
    "Copy Organize_Pub_Date_Fields.json and paste into OpenRefine\n",
    "\n",
    "## Organize URLs\n",
    "\n",
    "Copy Organize_URL_Fields_1.json and paste into OpenRefine\n",
    "\n",
    "Open a text filter for \"Fields\", perform any clustering if appropriate, click on the number of choices to get the facet choices as TSV, paste into variable \"URL_Headers\" below, and run cell\n"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 162,
   "metadata": {},
   "outputs": [],
   "source": [
    "URL_Headers = \"\"\"\n",
    "856$u\t521\n",
    "Celebration of Tenure website\t1\n",
    "EBSCOhost\t1\n",
    "Field #1 856$u\t2\n",
    "Field #2 856$u\t1\n",
    "Oxford Scholarship Online\t3179\n",
    "\"\"\""
   ]
  },
  {
   "source": [
    "Copy Pivot_Fields_and_Values.json and paste into OpenRefine\n",
    "\n",
    "Set \"i\" to the column number of column \"020$a\" and run cell"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 163,
   "metadata": {},
   "outputs": [],
   "source": [
    "URL_Headers = URL_Headers.split(\"\\n\")[1:-1] # The splice removes elements created by having the opening and closing quotes on their own lines\n",
    "Header_Names = []\n",
    "for Header in URL_Headers:\n",
    "    Header = Header.rstrip(\"1234567890\")\n",
    "    Header = Header.rstrip(\"\\t\")\n",
    "    Header_Names.append(Header)\n",
    "\n",
    "with open('JSON_Output.txt', 'w') as For_OpenRefine:\n",
    "    For_OpenRefine.write(\"[\")\n",
    "    i = 9\n",
    "    for Header in Header_Names:\n",
    "        Template_String = f\"\"\"\n",
    "            {{\n",
    "                \"op\": \"core/text-transform\",\n",
    "                \"engineConfig\": {{\n",
    "                \"facets\": [],\n",
    "                \"mode\": \"record-based\"\n",
    "                }},\n",
    "                \"columnName\": \"{Header}\",\n",
    "                \"expression\": \"grel:row.record.cells[\\\\\"{Header}\\\\\"].value[0]\",\n",
    "                \"onError\": \"keep-original\",\n",
    "                \"repeat\": false,\n",
    "                \"repeatCount\": 10,\n",
    "                \"description\": \"Fill up and down values in ``{Header}``\"\n",
    "            }},\n",
    "            {{\n",
    "                \"op\": \"core/blank-down\",\n",
    "                \"engineConfig\": {{\n",
    "                \"facets\": [],\n",
    "                \"mode\": \"record-based\"\n",
    "                }},\n",
    "                \"columnName\": \"{Header}\",\n",
    "                \"description\": \"Blank down cells in column ``{Header}``\"\n",
    "            }},\n",
    "            {{\n",
    "                \"op\": \"core/column-move\",\n",
    "                \"columnName\": \"{Header}\",\n",
    "                \"index\": {i},\n",
    "                \"description\": \"Move column ``{Header}`` to position {i}\"\n",
    "            }}\n",
    "        \"\"\"\n",
    "        For_OpenRefine.write(Template_String)\n",
    "        i += 1\n",
    "    For_OpenRefine.write(\"]\")"
   ]
  },
  {
   "source": [
    "Run all cells, then copy JSON_Output.txt and paste into OpenRefine\n",
    "\n",
    "Copy Remove_Blank_Rows_After_Pivot.json and paste into OpenRefine\n",
    "\n",
    "**897 and 710 fields not handled**\n",
    "\n",
    "## Organize Identifier Fields\n",
    "\n",
    "Copy Organize_Identifier_Fields.json and paste into OpenRefine\n",
    "\n",
    "Open a text filter for \"Fields\", click on the number of choices to get the facet choices as TSV, paste into variable \"Identifier_List\" below, and run cell"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 206,
   "metadata": {},
   "outputs": [],
   "source": [
    "Identifier_List = \"\"\"\n",
    "NhCcYBP\t214\n",
    "no label\t6\n",
    "OCoLC\t13\n",
    "StDuBDS\t3434\n",
    "UK-OxUP\t30\n",
    "YBPUID\t227\n",
    "\"\"\""
   ]
  },
  {
   "source": [
    "Copy Pivot_Fields_and_Values.json and paste into OpenRefine"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 207,
   "metadata": {},
   "outputs": [],
   "source": [
    "Identifier_List = Identifier_List.split(\"\\n\")[1:-1] # The splice removes elements created by having the opening and closing quotes on their own lines\n",
    "Identifiers = []\n",
    "for Identifier in Identifier_List:\n",
    "    Identifier = Identifier.rstrip(\"1234567890\")\n",
    "    Identifier = Identifier.rstrip(\"\\t\")\n",
    "    Identifiers.append(Identifier)\n",
    "\n",
    "Old_and_New_Headers = dict()\n",
    "for Identifier in Identifiers:\n",
    "    if Identifier_and_Name.get(Identifier) is None:\n",
    "        print(f\"{Identifier} doesn't have a value. Add one to the dictionary Identifier_and_Name at the top of the notebook and rerun all cells.\")\n",
    "        continue\n",
    "    Old_and_New_Headers[Identifier] = Identifier_and_Name.get(Identifier)\n",
    "\n",
    "Values_as_List = [l_org_code for l_org_code in Old_and_New_Headers.values()]\n",
    "Values_as_Set = set(Values_as_List)\n",
    "if len(Values_as_Set) < len(Values_as_List):\n",
    "    Duplicates_Check = dict()\n",
    "    for Set_Value in Values_as_Set:\n",
    "        Duplicates_Check[Set_Value] = 0\n",
    "        for List_Value in Values_as_List:\n",
    "            if Set_Value == List_Value:\n",
    "                Duplicates_Check[Set_Value] +=1\n",
    "\n",
    "    Repeated_Headers = []\n",
    "    for Key, Value in Duplicates_Check.items():\n",
    "        if Value > 1:\n",
    "            Repeated_Headers.append(Key)\n",
    "    print(\"The headers below were matched to multiple org codes in Identifier_List:\")\n",
    "    print(Repeated_Headers)\n"
   ]
  },
  {
   "source": [
    "Set \"i\" to the column number of column \"Author\""
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 208,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "with open('JSON_Output.txt', 'w') as For_OpenRefine:\n",
    "    For_OpenRefine.write(\"[\")\n",
    "    i = 8\n",
    "    for Key, Value in Old_and_New_Headers.items():\n",
    "        Template_String = f\"\"\"\n",
    "            {{\n",
    "                \"op\": \"core/column-addition\",\n",
    "                \"engineConfig\": {{\n",
    "                \"facets\": [],\n",
    "                \"mode\": \"row-based\"\n",
    "                }},\n",
    "                \"baseColumnName\": \"{Key}\",\n",
    "                \"expression\": \"grel:row.record.cells[\\\\\"{Key}\\\\\"].value[0]\",\n",
    "                \"onError\": \"set-to-blank\",\n",
    "                \"newColumnName\": \"{Value}\",\n",
    "                \"columnInsertIndex\": {i},\n",
    "                \"description\": \"Create column ``{Value}`` by filling up and down ``{Key}``\"\n",
    "            }},\n",
    "            {{\n",
    "                \"op\": \"core/blank-down\",\n",
    "                \"engineConfig\": {{\n",
    "                \"facets\": [],\n",
    "                \"mode\": \"record-based\"\n",
    "                }},\n",
    "                \"columnName\": \"{Value}\",\n",
    "                \"description\": \"Blank down cells in column ``{Value}``\"\n",
    "            }},\n",
    "            {{\n",
    "                \"op\": \"core/column-removal\",\n",
    "                \"columnName\": \"{Key}\",\n",
    "                \"description\": \"Remove column ``{Key}``\"\n",
    "            }}\n",
    "        \"\"\"\n",
    "        For_OpenRefine.write(Template_String)\n",
    "        i += 1\n",
    "    For_OpenRefine.write(\"]\")"
   ]
  },
  {
   "source": [
    "Run all cells, then copy JSON_Output.txt and paste into OpenRefine\n",
    "\n",
    "Copy Remove_Blank_Rows_After_Pivot.json and paste into OpenRefine\n",
    "\n",
    "## Organise ISBNs\n",
    "\n",
    "Copy Organize_ISBN_Fields_1.json and paste into OpenRefine\n",
    "\n",
    "Perform clustering on column \"ISBN Type\"\n",
    "\n",
    "Copy below and paste into OpenRefine\n",
    "\n",
    "`{`\n",
    "\n",
    "`\"op\": \"core/column-removal\",`\n",
    "\n",
    "`\"columnName\": \"ISBN Subfield\",`\n",
    "\n",
    "`\"description\": \"Remove column ISBN Subfield\"`\n",
    "\n",
    "`}`\n",
    "\n",
    "In OpenRefine, All > Edit Columns > Fill Down\n",
    "\n",
    "**No duplicates in sample, so need review on how deduping functions**\n",
    "\n",
    "Copy Organize_ISBN_Fields_2.json and paste into OpenRefine\n",
    "\n",
    "In OpenRefine, showing as rows, All > Edit Columns > Blank Down\n",
    "\n",
    "In OpenRefine, undo steps blanking down cells in columns \"ISBN\" and \"ISBN Type\"\n",
    "\n",
    "Open a text filter for \"ISBN Type\", click on the number of choices to get the facet choices as TSV, paste into variable \"ISBN_Fields\" below, and run cell"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 167,
   "metadata": {},
   "outputs": [],
   "source": [
    "ISBN_Types = \"\"\"\n",
    "eISBN 13\t524\n",
    "ISBN 13\t524\n",
    "\"\"\""
   ]
  },
  {
   "source": [
    "Copy Organize_ISBN_Fields_3.json and paste into OpenRefine"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 168,
   "metadata": {},
   "outputs": [],
   "source": [
    "ISBN_Types = ISBN_Types.split(\"\\n\")[1:-1] # The splice removes elements created by having the opening and closing quotes on their own lines\n",
    "ISBN_Fields = []\n",
    "for ISBN_Type in ISBN_Types:\n",
    "    ISBN_Type = ISBN_Type.rstrip(\"1234567890\")\n",
    "    ISBN_Type = ISBN_Type.rstrip(\"\\t\")\n",
    "    ISBN_Fields.append(ISBN_Type)\n",
    "\n",
    "with open('JSON_Output.txt', 'w') as For_OpenRefine:\n",
    "    For_OpenRefine.write(\"[\")\n",
    "    for ISBN_Type in ISBN_Fields:\n",
    "        Template_String = f\"\"\"\n",
    "            {{\n",
    "                \"op\": \"core/text-transform\",\n",
    "                \"engineConfig\": {{\n",
    "                \"facets\": [],\n",
    "                \"mode\": \"record-based\"\n",
    "                }},\n",
    "                \"columnName\": \"{ISBN_Type}\",\n",
    "                \"expression\": \"grel:row.record.cells[\\\\\"{ISBN_Type}\\\\\"].value[0]\",\n",
    "                \"onError\": \"keep-original\",\n",
    "                \"repeat\": false,\n",
    "                \"repeatCount\": 10,\n",
    "                \"description\": \"Fill up and down values in ``{ISBN_Type}``\"\n",
    "            }},\n",
    "            {{\n",
    "                \"op\": \"core/blank-down\",\n",
    "                \"engineConfig\": {{\n",
    "                \"facets\": [],\n",
    "                \"mode\": \"record-based\"\n",
    "                }},\n",
    "                \"columnName\": \"{ISBN_Type}\",\n",
    "                \"description\": \"Blank down cells in column ``{ISBN_Type}``\"\n",
    "            }}\n",
    "        \"\"\"\n",
    "        For_OpenRefine.write(Template_String)\n",
    "    For_OpenRefine.write(\"]\")"
   ]
  },
  {
   "source": [
    "Run all cells, then copy JSON_Output.txt and paste into OpenRefine\n",
    "\n",
    "Copy Remove_Blank_Rows_After_Pivot.json and paste into OpenRefine\n",
    "\n",
    "# Organize HOL\n",
    "\n",
    "> Start by loading Alpeh Sequential text file into OpenRefine with column widths 10,5,3\n",
    "\n",
    "Put the unique name of the OpenRefine project for the HOL records in the variable `HOL_Project_Name` and run the cell"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 169,
   "metadata": {},
   "outputs": [],
   "source": [
    "HOL_Project_Name = \"OHO_HOL\""
   ]
  },
  {
   "source": [
    "Copy Organize_Aleph_Sequential_for_HOL.json and paste into OpenRefine\n",
    "\n",
    "Open a text filter for \"Fields\", click on the number of choices to get the facet choices as TSV, paste into variable `Number_of_TKRs` below, and run cell"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "source": [
    "Number_of_TKRs = \"\"\"\n",
    "TKR 1\t524\n",
    "\"\"\""
   ],
   "cell_type": "code",
   "metadata": {},
   "execution_count": 170,
   "outputs": []
  },
  {
   "source": [
    "Copy below and paste into OpenRefine\n",
    "\n",
    "`{`\n",
    "\n",
    "`\"op\": \"core/key-value-columnize\",`\n",
    "\n",
    "`\"keyColumnName\": \"Fields\",`\n",
    "\n",
    "`\"valueColumnName\": \"Values\",`\n",
    "\n",
    "`\"noteColumnName\": \"\",`\n",
    "\n",
    "`\"description\": \"Pivot data so values in ``Fields`` are columns with values from ``Values``\"`\n",
    "\n",
    "`}`"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 171,
   "metadata": {},
   "outputs": [],
   "source": [
    "Number_of_TKRs = Number_of_TKRs.split(\"\\n\")[1:-1] # The splice removes elements created by having the opening and closing quotes on their own lines\n",
    "TKR_Fields = []\n",
    "for TKR in Number_of_TKRs:\n",
    "    TKR = TKR.rstrip(\"1234567890\")\n",
    "    TKR = TKR.rstrip(\"\\t\")\n",
    "    TKR_Fields.append(TKR)\n",
    "\n",
    "with open('JSON_Output.txt', 'w') as For_OpenRefine:\n",
    "    For_OpenRefine.write(\"[\")\n",
    "    for TKR_Field in TKR_Fields:\n",
    "        Template_String = f\"\"\"\n",
    "            {{\n",
    "                \"op\": \"core/text-transform\",\n",
    "                \"engineConfig\": {{\n",
    "                \"facets\": [],\n",
    "                \"mode\": \"record-based\"\n",
    "                }},\n",
    "                \"columnName\": \"{TKR_Field}\",\n",
    "                \"expression\": \"grel:row.record.cells[\\\\\"{TKR_Field}\\\\\"].value[0]\",\n",
    "                \"onError\": \"keep-original\",\n",
    "                \"repeat\": false,\n",
    "                \"repeatCount\": 10,\n",
    "                \"description\": \"Fill up and down values in ``{TKR_Field}``\"\n",
    "            }},\n",
    "            {{\n",
    "                \"op\": \"core/blank-down\",\n",
    "                \"engineConfig\": {{\n",
    "                \"facets\": [],\n",
    "                \"mode\": \"record-based\"\n",
    "                }},\n",
    "                \"columnName\": \"{TKR_Field}\",\n",
    "                \"description\": \"Blank down cells in column ``{TKR_Field}``\"\n",
    "            }}\n",
    "        \"\"\"\n",
    "        For_OpenRefine.write(Template_String)\n",
    "    For_OpenRefine.write(\"]\")"
   ]
  },
  {
   "source": [
    "Run all cells, then copy JSON_Output.txt and paste into OpenRefine\n",
    "\n",
    "**BEST WAY TO HANDLE MULTIPLE HOL FOR A BIB UNKNOWN: have column for number of HOL in BIB here, but don't know how to handle it if number is greater than one**\n",
    "\n",
    "Copy Organize_TKRs.json and paste into OpenRefine\n",
    "\n",
    "## Add HOL Data to BIB Project\n",
    "\n",
    "**cell.cross not finding matches between the same column in two projects from the same file with no transformations. Need to investigate the problem; possibly need to rever to older version of OpenRefine**\n",
    "\n",
    "http://127.0.0.1:3333/project?project=2263053648768&ui=%7B%22facets%22%3A%5B%5D%7D for HOL\n",
    "\n",
    "http://127.0.0.1:3333/project?project=2427886454110&ui=%7B%22facets%22%3A%5B%5D%7D for BIB\n"
   ],
   "cell_type": "markdown",
   "metadata": {}
  }
 ]
}