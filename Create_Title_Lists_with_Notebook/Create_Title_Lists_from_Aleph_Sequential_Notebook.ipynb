{
 "metadata": {
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.1-final"
  },
  "orig_nbformat": 2,
  "kernelspec": {
   "name": "python381jvsc74a57bd0808c0b65fb29d89f35c9ec8e00426afb986d0b65f026dc2bfd8b25d992fc8a8f",
   "display_name": "Python 3.8.1 32-bit"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2,
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 587,
   "metadata": {},
   "outputs": [],
   "source": [
    "Identifier_and_Name = {\n",
    "    \"Au-PeEL\": \"Ebook Library\",\n",
    "    \"AU-PeEL\": \"Ebook Library\",\n",
    "    \"CaONFJC\": \"MyiLibrary\",\n",
    "    \"CaPaEBR\": \"Ebrary\",\n",
    "    \"DE-He213\": \"Springer-Verlag\",\n",
    "    \"MiAaPQ\": \"ProQuest\",\n",
    "    \"NhCcYBP\": \"YBP\",\n",
    "    \"OCoLC\": \"OCLC\",\n",
    "    \"SFPDA_MiAaPQ\": \"ProQuest\",\n",
    "    \"YBPUID\": \"YBP ID\",\n",
    "    \"MIL\": \"MyiLibrary\",\n",
    "    \"EBR\": \"Ebrary\",\n",
    "    \"ebrary\": \"Ebrary (full name)\",\n",
    "    \"EBZ\": \"EBSCO\",\n",
    "    \"EBL\": \"Ebook Library (unofficial)\",\n",
    "    \"EBC\": \"Ebook Central\",\n",
    "    \"CaBNVSL\": \"SIAM\",\n",
    "    \"CaBNvSL\": \"SIAM\",\n",
    "    \"DcWaAPA\": \"APA\",\n",
    "    \"DNLM\": \"US Med Library\",\n",
    "    \"FR-PaOEC\": \"OECD\",\n",
    "    \"IN-ChSCO\": \"Scope e-Knowedge Center\",\n",
    "    \"MiFhGG\": \"Gale\",\n",
    "    \"StDuBDS\": \"Bibliographic Data Services\",\n",
    "    \"UtOrBLW\": \"Backstage Library Works\",\n",
    "    \"VaAlASP\": \"Alexander Street Press\",\n",
    "    \"EBS\": \"EBSCO\",\n",
    "    \"FANhCcYBP\": \"YBP (FA)\",\n",
    "    \"UK-OxUP\": \"Oxford UP\",\n",
    "    \"no_label\": \"Unlabeled\",\n",
    "}"
   ]
  },
  {
   "source": [
    "> Start by loading Alpeh Sequential text file into OpenRefine with column widths 10,6,2\n",
    "\n",
    "Put the unique name of the OpenRefine project for the BIB records in the variable `BIB_Project_Name` and run the cell"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 588,
   "metadata": {},
   "outputs": [],
   "source": [
    "BIB_Project_Name = \"wiley_bib_3 8 2021 txt\""
   ]
  },
  {
   "source": [
    "# Organize BIB Record\n",
    "\n",
    "## Organize MARC Fields and Subfields\n",
    "Copy Organize_Alpeh_Sequential_for_BIB.json and paste into OpenRefine"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "source": [
    "## Pivot Subfields into Columns\n",
    "Use a filter on \"No Field Number\" to select the following subfields, invert, then remove all matching rows:\n",
    "\n",
    "- 020$a\n",
    "- 020$q\n",
    "- 020$z\n",
    "- 024$2\n",
    "- 024$a\n",
    "- 035$a\n",
    "- 245$a\n",
    "- 245$b\n",
    "- 245$c\n",
    "- 245$n\n",
    "- 250$a\n",
    "- 264$b\n",
    "- 264$c\n",
    "- 710$a\n",
    "- 710$e\n",
    "- 776$i\n",
    "- 776$z\n",
    "- 856$3\n",
    "- 856$u\n",
    "- 856$z\n",
    "- 897$a\n",
    "- 897$e\n",
    "\n",
    "Open a text filter for \"Fields,\" click on the number of choices to get the facet choices as TSV, paste into variable \"Columns\" below, and run cell"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 589,
   "metadata": {},
   "outputs": [],
   "source": [
    "Columns = \"\"\"\n",
    "020$a\t274\n",
    "020$z\t2\n",
    "024$2\t390\n",
    "024$a\t539\n",
    "035$a\t3319\n",
    "245$a\t3427\n",
    "245$b\t892\n",
    "245$c\t1393\n",
    "245$n\t63\n",
    "250$a\t278\n",
    "264$b\t3039\n",
    "264$c\t2124\n",
    "776$i\t1314\n",
    "776$z\t1538\n",
    "856$3\t1031\n",
    "856$u\t1770\n",
    "856$z\t392\n",
    "Field #1 020$a\t1118\n",
    "Field #1 020$q\t467\n",
    "Field #1 020$z\t33\n",
    "Field #1 024$2\t26\n",
    "Field #1 024$a\t36\n",
    "Field #1 035$a\t108\n",
    "Field #1 264$b\t454\n",
    "Field #1 264$c\t299\n",
    "Field #1 776$i\t889\n",
    "Field #1 776$z\t83\n",
    "Field #1 856$3\t2\n",
    "Field #1 856$u\t1657\n",
    "Field #1 856$z\t1653\n",
    "Field #10 020$a\t73\n",
    "Field #10 020$q\t70\n",
    "Field #10 020$z\t82\n",
    "Field #10 856$u\t76\n",
    "Field #10 856$z\t76\n",
    "Field #11 020$a\t41\n",
    "Field #11 020$q\t29\n",
    "Field #11 020$z\t34\n",
    "Field #11 856$u\t55\n",
    "Field #11 856$z\t55\n",
    "Field #12 020$a\t31\n",
    "Field #12 020$q\t23\n",
    "Field #12 020$z\t27\n",
    "Field #12 856$u\t43\n",
    "Field #12 856$z\t43\n",
    "Field #13 020$a\t13\n",
    "Field #13 020$q\t17\n",
    "Field #13 020$z\t21\n",
    "Field #13 856$u\t33\n",
    "Field #13 856$z\t33\n",
    "Field #14 020$a\t6\n",
    "Field #14 020$q\t7\n",
    "Field #14 020$z\t11\n",
    "Field #14 856$u\t27\n",
    "Field #14 856$z\t27\n",
    "Field #15 020$a\t1\n",
    "Field #15 020$q\t3\n",
    "Field #15 020$z\t7\n",
    "Field #15 856$u\t21\n",
    "Field #15 856$z\t21\n",
    "Field #16 020$a\t1\n",
    "Field #16 020$q\t2\n",
    "Field #16 020$z\t4\n",
    "Field #16 856$u\t14\n",
    "Field #16 856$z\t14\n",
    "Field #17 020$z\t2\n",
    "Field #17 856$u\t10\n",
    "Field #17 856$z\t10\n",
    "Field #18 020$z\t2\n",
    "Field #18 856$u\t2\n",
    "Field #18 856$z\t2\n",
    "Field #19 020$z\t1\n",
    "Field #19 856$u\t2\n",
    "Field #19 856$z\t2\n",
    "Field #2 020$a\t1126\n",
    "Field #2 020$q\t466\n",
    "Field #2 020$z\t24\n",
    "Field #2 024$2\t9\n",
    "Field #2 024$a\t36\n",
    "Field #2 035$a\t108\n",
    "Field #2 264$b\t352\n",
    "Field #2 264$c\t70\n",
    "Field #2 776$i\t298\n",
    "Field #2 776$z\t88\n",
    "Field #2 856$3\t3\n",
    "Field #2 856$u\t1655\n",
    "Field #2 856$z\t1651\n",
    "Field #20 020$z\t1\n",
    "Field #20 856$u\t2\n",
    "Field #20 856$z\t2\n",
    "Field #21 020$z\t1\n",
    "Field #21 856$u\t1\n",
    "Field #21 856$z\t1\n",
    "Field #3 020$a\t837\n",
    "Field #3 020$q\t454\n",
    "Field #3 020$z\t135\n",
    "Field #3 035$a\t93\n",
    "Field #3 264$b\t77\n",
    "Field #3 264$c\t1\n",
    "Field #3 776$i\t64\n",
    "Field #3 776$z\t9\n",
    "Field #3 856$u\t1030\n",
    "Field #3 856$z\t1030\n",
    "Field #4 020$a\t824\n",
    "Field #4 020$q\t448\n",
    "Field #4 020$z\t114\n",
    "Field #4 035$a\t2\n",
    "Field #4 264$b\t15\n",
    "Field #4 776$i\t13\n",
    "Field #4 776$z\t2\n",
    "Field #4 856$u\t634\n",
    "Field #4 856$z\t634\n",
    "Field #5 020$a\t440\n",
    "Field #5 020$q\t321\n",
    "Field #5 020$z\t347\n",
    "Field #5 264$b\t4\n",
    "Field #5 776$i\t3\n",
    "Field #5 776$z\t1\n",
    "Field #5 856$u\t436\n",
    "Field #5 856$z\t436\n",
    "Field #6 020$a\t463\n",
    "Field #6 020$q\t302\n",
    "Field #6 020$z\t289\n",
    "Field #6 264$b\t2\n",
    "Field #6 856$u\t303\n",
    "Field #6 856$z\t303\n",
    "Field #7 020$a\t212\n",
    "Field #7 020$q\t207\n",
    "Field #7 020$z\t282\n",
    "Field #7 856$u\t203\n",
    "Field #7 856$z\t203\n",
    "Field #8 020$a\t202\n",
    "Field #8 020$q\t162\n",
    "Field #8 020$z\t193\n",
    "Field #8 856$u\t148\n",
    "Field #8 856$z\t148\n",
    "Field #9 020$a\t86\n",
    "Field #9 020$q\t102\n",
    "Field #9 020$z\t151\n",
    "Field #9 856$u\t111\n",
    "Field #9 856$z\t111\n",
    "\"\"\""
   ]
  },
  {
   "source": [
    "**Indicator columns deleted at this point--unsure how to handle/how or if to preserve beyond this point**\n",
    "\n",
    "Copy Pivot_Fields_and_Values.json and paste into OpenRefine"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 590,
   "metadata": {},
   "outputs": [],
   "source": [
    "Columns = Columns.split(\"\\n\")[1:-1] # The splice removes elements created by having the opening and closing quotes on their own lines\n",
    "Column_Names = []\n",
    "for Column in Columns:\n",
    "    Column = Column.rstrip(\"1234567890\")\n",
    "    Column = Column.rstrip(\"\\t\")\n",
    "    Column_Names.append(Column)\n",
    "\n",
    "with open('JSON_Output.txt', 'w') as For_OpenRefine:\n",
    "    For_OpenRefine.write(\"[\")\n",
    "    for Column in Column_Names:\n",
    "        Template_String = f\"\"\"\n",
    "            {{\n",
    "                \"op\": \"core/text-transform\",\n",
    "                \"engineConfig\": {{\n",
    "                \"facets\": [],\n",
    "                \"mode\": \"record-based\"\n",
    "                }},\n",
    "                \"columnName\": \"{Column}\",\n",
    "                \"expression\": \"grel:row.record.cells[\\\\\"{Column}\\\\\"].value[0]\",\n",
    "                \"onError\": \"keep-original\",\n",
    "                \"repeat\": false,\n",
    "                \"repeatCount\": 10,\n",
    "                \"description\": \"Fill up and down values in ``{Column}``\"\n",
    "            }},\n",
    "            {{\n",
    "                \"op\": \"core/blank-down\",\n",
    "                \"engineConfig\": {{\n",
    "                \"facets\": [],\n",
    "                \"mode\": \"record-based\"\n",
    "                }},\n",
    "                \"columnName\": \"{Column}\",\n",
    "                \"description\": \"Blank down cells in column ``{Column}``\"\n",
    "            }},\n",
    "        \"\"\"\n",
    "        For_OpenRefine.write(Template_String)\n",
    "    For_OpenRefine.write(\"]\")"
   ]
  },
  {
   "source": [
    "Run all cells, then copy JSON_Output.txt and paste into OpenRefine\n",
    "\n",
    "Copy Remove_Blank_Rows_After_Pivot.json and paste into OpenRefine"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 591,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def Column_Order_as_Letter(MARC_Tag):\n",
    "    if MARC_Tag == \"020$a\":\n",
    "        return \"A\"\n",
    "    elif MARC_Tag == \"020$z\":\n",
    "        return \"B\"\n",
    "    elif MARC_Tag == \"776$z\":\n",
    "        return \"C\"\n",
    "    elif MARC_Tag == \"020$q\":\n",
    "        return \"D\"\n",
    "    elif MARC_Tag == \"776$i\":\n",
    "        return \"E\"\n",
    "    elif MARC_Tag == \"024$a\":\n",
    "        return \"F\"\n",
    "    elif MARC_Tag == \"024$2\":\n",
    "        return \"G\"\n",
    "    elif MARC_Tag == \"035$a\":\n",
    "        return \"H\"\n",
    "    elif MARC_Tag == \"710$a\":\n",
    "        return \"I\"\n",
    "    elif MARC_Tag == \"710$e\":\n",
    "        return \"J\"\n",
    "    elif MARC_Tag == \"897$a\":\n",
    "        return \"K\"\n",
    "    elif MARC_Tag == \"897$e\":\n",
    "        return \"L\"\n",
    "    elif MARC_Tag == \"856$u\":\n",
    "        return \"M\"\n",
    "    elif MARC_Tag == \"856$z\":\n",
    "        return \"N\"\n",
    "    elif MARC_Tag == \"856$3\":\n",
    "        return \"O\"\n",
    "    elif MARC_Tag == \"264$c\":\n",
    "        return \"P\"\n",
    "    elif MARC_Tag == \"264$b\":\n",
    "        return \"Q\"\n",
    "    elif MARC_Tag == \"245$c\":\n",
    "        return \"R\"\n",
    "    elif MARC_Tag == \"250$a\":\n",
    "        return \"S\"\n",
    "    elif MARC_Tag == \"245$n\":\n",
    "        return \"T\"\n",
    "    elif MARC_Tag == \"245$b\":\n",
    "        return \"U\"\n",
    "    elif MARC_Tag == \"245$a\":\n",
    "        return \"V\"\n",
    "    # No \"else\" statement because if there's a problem here, it will require manual intervention\n",
    "\n",
    "Column_Order = {\n",
    "    \"A\": {},\n",
    "    \"B\": {},\n",
    "    \"C\": {},\n",
    "    \"D\": {},\n",
    "    \"E\": {},\n",
    "    \"F\": {},\n",
    "    \"G\": {},\n",
    "    \"H\": {},\n",
    "    \"I\": {},\n",
    "    \"J\": {},\n",
    "    \"K\": {},\n",
    "    \"L\": {},\n",
    "    \"M\": {},\n",
    "    \"N\": {},\n",
    "    \"O\": {},\n",
    "    \"P\": {},\n",
    "    \"Q\": {},\n",
    "    \"R\": {},\n",
    "    \"S\": {},\n",
    "    \"T\": {},\n",
    "    \"U\": {},\n",
    "    \"V\": {},\n",
    "}\n",
    "\n",
    "# Create nested dictionary for ordering columns\n",
    "for Column in Column_Names:\n",
    "    if \" \" in Column: # Has field number\n",
    "        Field_Number = int(Column.split(\" \")[1][1:])\n",
    "        Ordering_Letter = Column_Order_as_Letter(Column.split(\" \")[2])\n",
    "        Column_Order[Ordering_Letter][Field_Number] = Column\n",
    "    else:\n",
    "        Ordering_Letter = Column_Order_as_Letter(Column)\n",
    "        Column_Order[Ordering_Letter][0] = Column\n",
    "\n",
    "# Create markers to ensure that all first column in pivots exist\n",
    "if not Column_Order[\"Q\"].get(0): # If there's no column that's just \"264$b\"\n",
    "    Column_Order[\"Q\"][0] = \"264$b_marker\"\n",
    "if not Column_Order[\"P\"].get(0): # If there's no column that's jsut \"264$c\"\n",
    "    Column_Order[\"p\"][0] = \"264$c_marker\"\n",
    "if not Column_Order[\"O\"].get(0): # If there's no column that's just \"856$u\"\n",
    "    Column_Order[\"O\"][0] = \"856$u_marker\"\n",
    "if not Column_Order[\"H\"].get(0): # If there's no column that's just \"035$a\"\n",
    "    Column_Order[\"H\"][0] = \"035$a_marker\"\n",
    "if not Column_Order[\"A\"].get(0): # If there's no column that's just \"020$a\"\n",
    "    Column_Order[\"A\"][0] = \"020$a_marker\"\n",
    "\n",
    "# Sort by field order within tags\n",
    "for key, value in Column_Order.items():\n",
    "    value = dict(sorted(value.items()))\n",
    "    Column_Order[key] = value\n",
    "\n",
    "# Create list of column values and markers for columns needed for pivots in order\n",
    "Column_Order_Values = []\n",
    "for Outer_Value in Column_Order.values():\n",
    "    for Inner_Value in Outer_Value.values():\n",
    "        Column_Order_Values.append(Inner_Value)\n",
    "\n",
    "# Create dictionary for adding columns needed for pivots and list of existing columns for adding to JSON \n",
    "Pivot_Addition_Column_Indexes = {Column_Value[0:5]: Column_Order_Values.index(Column_Value)+2 for Column_Value in Column_Order_Values if \"_marker\" in Column_Value}\n",
    "Column_Order_Values = ['\"' + Column_Value + '\"' for Column_Value in Column_Order_Values if \"_marker\" not in Column_Value] #if \"_marker\" not in Column_Value\n",
    "Reordering_String = \",\\n\".join(Column_Order_Values)\n",
    "\n",
    "# Create final JSON for ordering columns\n",
    "with open('JSON_Output.txt', 'w') as For_OpenRefine:\n",
    "    Template_String = f\"\"\"\n",
    "        [\n",
    "            {{\n",
    "                \"op\": \"core/column-addition\",\n",
    "                \"description\": \"Create column ``Count``\",\n",
    "                \"engineConfig\": {{\n",
    "                    \"facets\": [],\n",
    "                    \"mode\": \"record-based\"\n",
    "                }},\n",
    "                \"newColumnName\": \"Count\",\n",
    "                \"columnInsertIndex\": 1,\n",
    "                \"baseColumnName\": \"SYS Number\",\n",
    "                \"expression\": \"grel:row.record.cells[\\\\\"SYS Number\\\\\"].value[0]+\\\\\"-\\\\\"+toString(row.index-row.record.fromRowIndex+1)\",\n",
    "                \"onError\": \"set-to-blank\"\n",
    "            }},\n",
    "            {{\n",
    "                \"op\": \"core/column-reorder\",\n",
    "                \"columnNames\": [\n",
    "                    \"SYS Number\",\n",
    "                    \"Count\",\n",
    "                    {Reordering_String}\n",
    "                ],\n",
    "                \"description\": \"Reorder columns\"\n",
    "            }}\n",
    "    \"\"\"\n",
    "    For_OpenRefine.write(Template_String)\n",
    "    for Column_Name, Column_Position in Pivot_Addition_Column_Indexes.items():\n",
    "        Template_String = f\"\"\"\n",
    "            {{\n",
    "                \"op\": \"core/column-addition\",\n",
    "                \"engineConfig\": {{\n",
    "                    \"facets\": [],\n",
    "                    \"mode\": \"record-based\"\n",
    "                }},\n",
    "                \"baseColumnName\": \"SYS Number\",\n",
    "                \"expression\": \"grel:null\",\n",
    "                \"onError\": \"set-to-blank\",\n",
    "                \"newColumnName\": \"{Column_Name}\",\n",
    "                \"columnInsertIndex\": {Column_Position},\n",
    "                \"description\": \"Create column ``{Column_Name}`` for pivoting\"\n",
    "            }}\n",
    "        \"\"\"\n",
    "        For_OpenRefine.write(Template_String)\n",
    "    For_OpenRefine.write(\"]\")"
   ]
  },
  {
   "source": [
    "Run all cells, then copy JSON_Output.txt and paste into OpenRefine\n",
    "\n",
    "Copy Organize_Rarely_Duplicated_Fields.json and paste into OpenRefine\n",
    "\n",
    "## Organize Publisher and Pub Date Fields\n",
    "\n",
    "**Multiple publisher fields handled by combining htem with `]|[` seperator; is there a better option?**\n",
    "\n",
    "Copy Organize_Publisher_Fields.json and paste into OpenRefine\n",
    "\n",
    "**PUB DATE ABLE TO HANDLE SAME DATE MULTIPLE TIMES--NEED TO FIGURE OUT STRATEGY FOR IF WE WANT TO PRESERVE BOTH DATES**\n",
    "\n",
    "Copy Organize_Pub_Date_Fields.json and paste into OpenRefine\n",
    "\n",
    "## Organize URLs\n",
    "\n",
    "Copy Organize_URL_Fields.json and paste into OpenRefine\n",
    "* If the row's value in \"Fields\" is null, the value in \"Values\" won't be retained through the pivot\n",
    "\n",
    "Open a text filter for \"Fields\", perform any clustering if appropriate, click on the number of choices to get the facet choices as TSV, paste into variable \"URL_Headers\" below, and run cell\n"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 592,
   "metadata": {},
   "outputs": [],
   "source": [
    "URL_Headers = \"\"\"\n",
    "856$u\t400\n",
    "ABI/INFORM Archive Complete*\t16\n",
    "ABI/INFORM Collection*\t113\n",
    "ABI/INFORM Global*\t111\n",
    "ABI/INFORM Trade & Industry*\t7\n",
    "Academic ASAP*\t27\n",
    "Academic Search Complete*\t622\n",
    "ACS Legacy Archives*\t1\n",
    "ACSESS Digital Library*\t1\n",
    "AgEcon Search*\t3\n",
    "American Geophysical Union Digital Library*\t8\n",
    "American Society of Plant Biologists (ASPB)*\t1\n",
    "Anthrosource (Wiley)*\t22\n",
    "Applied Science & Technology Source*\t39\n",
    "Art & Architecture Source*\t14\n",
    "Art Full Text (H.W. Wilson)*\t3\n",
    "ASTM Compass*\t1\n",
    "ASTM Standards and Engineering Digital Library*\t1\n",
    "ATLA Religion Database with ATLASerials (EBSCO)*\t10\n",
    "Available from Wiley Online\t1\n",
    "Biological Science Database*\t69\n",
    "BioMed Central*\t2\n",
    "BioOne Complete*\t13\n",
    "BioOne Open Access*\t2\n",
    "BioOne.1*\t10\n",
    "Blackwell Reference Online|An electronic book accessible through the World Wide Web; click for information\t1\n",
    "Business Abstracts with Full Text (H.W. Wilson)*\t15\n",
    "Business Insights: Essentials*\t25\n",
    "Business Source Complete*\t230\n",
    "Cambridge Journals Online*\t13\n",
    "Chicago Complete Collection - Full Run*\t1\n",
    "CINAHL Plus with Full Text*\t43\n",
    "ClinicalKey eJournals*\t4\n",
    "ClinicalKey Flex*\t3\n",
    "Columbia International Affairs Online (CIAO)*\t1\n",
    "Communication & Mass Media Complete*\t9\n",
    "Criminal Justice Database*\t17\n",
    "DOAJ: Directory of Open Access Journals*\t160\n",
    "Earth, Atmospheric & Aquatic Science Database*\t54\n",
    "EBSCO Open Access Journals*\t137\n",
    "EBSCOhost\t5\n",
    "Education Full Text (H.W. Wilson) *\t28\n",
    "Education Source*\t108\n",
    "Ethnic News Watch (ProQuest)*\t3\n",
    "Field #1 856$u\t4\n",
    "Field #2 856$u\t1\n",
    "Free Access Journals (HighWire)*\t2\n",
    "Free Medical Journals*\t1\n",
    "Gale Academic OneFile Select*\t80\n",
    "Gale Academic OneFile*\t117\n",
    "Gale Business: Entrepreneurship*\t5\n",
    "Gale General OneFile*\t83\n",
    "Gale Health and Wellness*\t12\n",
    "Gale In Context: Biography*\t6\n",
    "Gale Literature Resource Center*\t1\n",
    "Gale OneFile: Business*\t23\n",
    "Gale OneFile: Communications and Mass Media*\t2\n",
    "Gale OneFile: Criminal Justice*\t18\n",
    "Gale OneFile: Culinary Arts*\t3\n",
    "Gale OneFile: Economics and Theory*\t14\n",
    "Gale OneFile: Entrepreneurship*\t3\n",
    "Gale OneFile: Environmental Studies and Policy*\t13\n",
    "Gale OneFile: Gardening and Horticulture*\t4\n",
    "Gale OneFile: Health and Medicine*\t33\n",
    "Gale OneFile: Hospitality and Tourism*\t2\n",
    "Gale OneFile: LegalTrac*\t2\n",
    "Gale OneFile: Military and Intelligence*\t11\n",
    "Gale OneFile: Psychology*\t23\n",
    "Gale OneFile: Science*\t4\n",
    "Gale OneFile: Vocations and Careers*\t4\n",
    "Gale OneFile: War and Terrorism*\t3\n",
    "Gender Watch (ProQuest)*\t3\n",
    "General Reference Center Gold*\t2\n",
    "General Science Full Text (H.W. Wilson)*\t1\n",
    "Health & Wellness Resource Center (w/alt health module)*\t11\n",
    "Hein Online Criminal Justice & Criminology*\t9\n",
    "HeinOnline Congress and the Courts*\t1\n",
    "HeinOnline Criminal Justice Journals*\t3\n",
    "HeinOnline International and Non-U.S. Law Journals*\t6\n",
    "HeinOnline Law Journal Library*\t31\n",
    "Hindawi Open Access Journals*\t14\n",
    "Hospitality & Tourism Complete*\t3\n",
    "Humanities Full Text (H.W. Wilson)*\t6\n",
    "Humanities Source*\t55\n",
    "IngentaConnect Open Access Publications*\t43\n",
    "J-STAGE*\t1\n",
    "Journals@Ovid*\t20\n",
    "JSTOR Archive Collection*\t2\n",
    "JSTOR Arts & Sciences Archive Collection*\t123\n",
    "JSTOR Biological Sciences Archive Collection*\t29\n",
    "JSTOR Business Archive Collection*\t23\n",
    "JSTOR Ecology & Botany I Archive Collection*\t16\n",
    "JSTOR Free Early Journal Content*\t7\n",
    "JSTOR Language & Literature Archive Collection*\t2\n",
    "JSTOR Life Sciences Archive Collection*\t29\n",
    "JSTOR Music Archive Collection*\t1\n",
    "JSTOR Open Access Journals*\t2\n",
    "Knovel\t1\n",
    "Library Literature & Information Science Full Text (H.W. Wilson)*\t1\n",
    "Library, Information Science & Technology Abstracts with Full Text*\t6\n",
    "Lippincott Williams and Wilkins*\t1\n",
    "LWW Total Access Collection 2019 with Neurology*\t6\n",
    "MasterFILE Premier*\t2\n",
    "Military & Government Collection*\t6\n",
    "Nexis Uni*\t6\n",
    "Ovid Open Access Journal Collection*\t62\n",
    "Oxford Open*\t6\n",
    "Oxford University Press*\t36\n",
    "Performing Arts Periodicals Database*\t3\n",
    "Periodicals Archive Online Foundation Collection*\t7\n",
    "Project MUSE - Premium Collection*\t9\n",
    "ProQuest American Periodicals*\t2\n",
    "ProQuest Ebook Central\t3\n",
    "Proquest Periodicals Archive Online Foundation Collection*\t12\n",
    "ProQuest SciTech Collection*\t140\n",
    "PsycARTICLES (APA)*\t1\n",
    "PsycARTICLES (ProQuest)*\t1\n",
    "PubMed Central (PMC) Open Access*\t116\n",
    "PubMed Central (PMC)*\t28\n",
    "Readers' Guide Full Text Mega (H.W. Wilson)*\t2\n",
    "SAGE Deep Backfile Upgrade 2012*\t1\n",
    "SAGE Premier 2020*\t14\n",
    "SAGE Pure Gold Open Access Journals*\t1\n",
    "SAO/NASA Astrophysics Data System (ADS)*\t3\n",
    "ScienceDirect Open Access Titles*\t11\n",
    "ScienceDirect*\t17\n",
    "SciTech Premium Collection*\t140\n",
    "Social Science Premium Collection*\t128\n",
    "Social Sciences Full Text (H.W. Wilson)*\t37\n",
    "Society for Endocrinology Journals*\t1\n",
    "SPORTDiscus with Full Text*\t21\n",
    "Springer Nature Journals*\t12\n",
    "SpringerLINK (ISTEX - Licences Nationales)*\t8\n",
    "SpringerLINK Archive (CRKN)*\t5\n",
    "SpringerLINK Chemistry and Materials Science Archives*\t1\n",
    "SpringerLINK Medicine Archives*\t1\n",
    "SpringerOpen*\t3\n",
    "Table of contents only\t1\n",
    "Taylor & Francis Education Archive 2017*\t2\n",
    "Taylor & Francis Geography Planning & Urban Environment Archive 2017*\t4\n",
    "Taylor & Francis Open*\t3\n",
    "Taylor & Francis*\t13\n",
    "Thieme Connect*\t1\n",
    "Wiley Online Library\t1042\n",
    "Wiley Online Library Backfiles*\t1000\n",
    "Wiley Online Library Database Model 2019*\t1\n",
    "Wiley Online Library Database Model 2020*\t1644\n",
    "Wiley Online Library Free Journal Backfiles (formerly Blackwell Synergy)*\t82\n",
    "Wiley Online Library Open Access*\t307\n",
    "\"\"\""
   ]
  },
  {
   "source": [
    "Copy Pivot_Fields_and_Values.json and paste into OpenRefine\n",
    "\n",
    "Set \"i\" to the column number of column \"020$a\" and run cell"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 593,
   "metadata": {},
   "outputs": [],
   "source": [
    "URL_Headers = URL_Headers.split(\"\\n\")[1:-1] # The splice removes elements created by having the opening and closing quotes on their own lines\n",
    "Header_Names = []\n",
    "for Header in URL_Headers:\n",
    "    Header = Header.rstrip(\"1234567890\")\n",
    "    Header = Header.rstrip(\"\\t\")\n",
    "    Header_Names.append(Header)\n",
    "\n",
    "with open('JSON_Output.txt', 'w') as For_OpenRefine:\n",
    "    For_OpenRefine.write(\"[\")\n",
    "    i = 9\n",
    "    for Header in Header_Names:\n",
    "        Template_String = f\"\"\"\n",
    "            {{\n",
    "                \"op\": \"core/text-transform\",\n",
    "                \"engineConfig\": {{\n",
    "                \"facets\": [],\n",
    "                \"mode\": \"record-based\"\n",
    "                }},\n",
    "                \"columnName\": \"{Header}\",\n",
    "                \"expression\": \"grel:row.record.cells[\\\\\"{Header}\\\\\"].value[0]\",\n",
    "                \"onError\": \"keep-original\",\n",
    "                \"repeat\": false,\n",
    "                \"repeatCount\": 10,\n",
    "                \"description\": \"Fill up and down values in ``{Header}``\"\n",
    "            }},\n",
    "            {{\n",
    "                \"op\": \"core/blank-down\",\n",
    "                \"engineConfig\": {{\n",
    "                \"facets\": [],\n",
    "                \"mode\": \"record-based\"\n",
    "                }},\n",
    "                \"columnName\": \"{Header}\",\n",
    "                \"description\": \"Blank down cells in column ``{Header}``\"\n",
    "            }},\n",
    "            {{\n",
    "                \"op\": \"core/column-move\",\n",
    "                \"columnName\": \"{Header}\",\n",
    "                \"index\": {i},\n",
    "                \"description\": \"Move column ``{Header}`` to position {i}\"\n",
    "            }}\n",
    "        \"\"\"\n",
    "        For_OpenRefine.write(Template_String)\n",
    "        i += 1\n",
    "    For_OpenRefine.write(\"]\")"
   ]
  },
  {
   "source": [
    "Run all cells, then copy JSON_Output.txt and paste into OpenRefine\n",
    "\n",
    "Copy Remove_Blank_Rows_After_Pivot.json and paste into OpenRefine\n",
    "\n",
    "**897 and 710 fields not handled**\n",
    "\n",
    "## Organize 035$a Identifier Fields\n",
    "\n",
    "Copy Organize_035_Identifier_Fields.json and paste into OpenRefine\n",
    "\n",
    "Open a text filter for \"Fields\", evaluate any remaining options with asterists at the end, and remove the asterisk if the label is to remain or the lable if the value doesn't need to be retaiend\n",
    "\n",
    "In the text filter for \"Fields\", click on the number of choices to get the facet choices as TSV, paste into variable \"Identifier_List\" below, and run cell"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 594,
   "metadata": {},
   "outputs": [],
   "source": [
    "Identifier_List = \"\"\"\n",
    "AU-PeEL\t34\n",
    "CaONFJC\t1\n",
    "CaPaEBR\t1\n",
    "EBL\t35\n",
    "ebrary\t1\n",
    "EBZ\t1989\n",
    "NhCcYBP\t64\n",
    "no_label\t7\n",
    "OCoLC\t1377\n",
    "YBPUID\t61\n",
    "YBPUID #1\t1\n",
    "\"\"\""
   ]
  },
  {
   "source": [
    "Copy Pivot_Fields_and_Values.json and paste into OpenRefine"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 595,
   "metadata": {},
   "outputs": [],
   "source": [
    "Identifier_List = Identifier_List.split(\"\\n\")[1:-1] # The splice removes elements created by having the opening and closing quotes on their own lines\n",
    "Identifiers = []\n",
    "for Identifier in Identifier_List:\n",
    "    Identifier = Identifier.rstrip(\"1234567890\")\n",
    "    Identifier = Identifier.rstrip(\"\\t\")\n",
    "    Identifiers.append(Identifier)\n",
    "\n",
    "Old_and_New_Headers = dict()\n",
    "for Identifier in Identifiers:\n",
    "    if len(Identifier.split(\" \")) == 1:\n",
    "        if Identifier_and_Name.get(Identifier) is None:\n",
    "            print(f\"{Identifier} doesn't have a value. Add one to the dictionary Identifier_and_Name at the top of the notebook and rerun all cells.\")\n",
    "            continue\n",
    "        Old_and_New_Headers[Identifier] = Identifier_and_Name.get(Identifier)\n",
    "    else: # This handles when multiple IDs with the same org code exist in a record\n",
    "        Repeated_Org_Code = Identifier.split(\" \")[0]\n",
    "        if Identifier_and_Name.get(Repeated_Org_Code) is None:\n",
    "            # No statement output because it would be repetitive\n",
    "            continue\n",
    "        Column_Name_Base = Identifier_and_Name.get(Repeated_Org_Code)\n",
    "        Old_and_New_Headers[Identifier] = Column_Name_Base + \" \" + Identifier.split(\" \")[1]\n",
    "\n",
    "Values_as_List = [Future_Column_Headers for Future_Column_Headers in Old_and_New_Headers.values()]\n",
    "Values_as_Set = set(Values_as_List)\n",
    "if len(Values_as_Set) < len(Values_as_List):\n",
    "    Duplicates_Check = dict()\n",
    "    for Set_Value in Values_as_Set:\n",
    "        Duplicates_Check[Set_Value] = 0\n",
    "        for List_Value in Values_as_List:\n",
    "            if Set_Value == List_Value:\n",
    "                Duplicates_Check[Set_Value] +=1\n",
    "\n",
    "    Repeated_Headers = []\n",
    "    for Key, Value in Duplicates_Check.items():\n",
    "        if Value > 1:\n",
    "            Repeated_Headers.append(Key)\n",
    "    print(\"The headers below were matched to multiple org codes in Identifier_List:\")\n",
    "    print(Repeated_Headers)\n"
   ]
  },
  {
   "source": [
    "Set \"i\" to the column number of column \"Author\""
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 603,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "with open('JSON_Output.txt', 'w') as For_OpenRefine:\n",
    "    For_OpenRefine.write(\"[\")\n",
    "    i = 8\n",
    "    for Key, Value in Old_and_New_Headers.items():\n",
    "        Template_String = f\"\"\"\n",
    "            {{\n",
    "                \"op\": \"core/column-addition\",\n",
    "                \"engineConfig\": {{\n",
    "                \"facets\": [],\n",
    "                \"mode\": \"row-based\"\n",
    "                }},\n",
    "                \"baseColumnName\": \"{Key}\",\n",
    "                \"expression\": \"grel:row.record.cells[\\\\\"{Key}\\\\\"].value[0]\",\n",
    "                \"onError\": \"set-to-blank\",\n",
    "                \"newColumnName\": \"{Value}\",\n",
    "                \"columnInsertIndex\": {i},\n",
    "                \"description\": \"Create column ``{Value}`` by filling up and down ``{Key}``\"\n",
    "            }},\n",
    "            {{\n",
    "                \"op\": \"core/blank-down\",\n",
    "                \"engineConfig\": {{\n",
    "                \"facets\": [],\n",
    "                \"mode\": \"record-based\"\n",
    "                }},\n",
    "                \"columnName\": \"{Value}\",\n",
    "                \"description\": \"Blank down cells in column ``{Value}``\"\n",
    "            }},\n",
    "            {{\n",
    "                \"op\": \"core/column-removal\",\n",
    "                \"columnName\": \"{Key}\",\n",
    "                \"description\": \"Remove column ``{Key}``\"\n",
    "            }}\n",
    "        \"\"\"\n",
    "        For_OpenRefine.write(Template_String)\n",
    "        i += 1\n",
    "    For_OpenRefine.write(\"]\")"
   ]
  },
  {
   "source": [
    "Run all cells, then copy JSON_Output.txt and paste into OpenRefine\n",
    "\n",
    "Copy Remove_Blank_Rows_After_Pivot.json and paste into OpenRefine\n",
    "\n",
    "## Organize Other Identifier ISBN_Fields\n",
    "\n",
    "Copy Organize_Other_Identifier_Fields.json and paste into OpenRefine\n",
    "\n",
    "Open a text filter for \"Fields\", change any field names if appropriate, click on the number of choices to get the facet choices as TSV, paste into variable \"Other_Identifiers\" below, and run cell"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Other_Identifiers = \"\"\"\n",
    "\"\"\""
   ]
  },
  {
   "source": [
    "Copy Pivot_Fields_and_Values.json and paste into OpenRefine"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "source": [
    "#024 loop"
   ],
   "cell_type": "code",
   "metadata": {},
   "execution_count": null,
   "outputs": []
  },
  {
   "source": [
    "Run all cells, then copy JSON_Output.txt and paste into OpenRefine\n",
    "\n",
    "Copy Remove_Blank_Rows_After_Pivot.json and paste into OpenRefine\n",
    "\n",
    "## Organise ISBNs\n",
    "\n",
    "Copy Organize_ISBN_Fields_1.json and paste into OpenRefine\n",
    "\n",
    "Perform clustering on column \"ISBN Type\"\n",
    "\n",
    "Copy Organize_ISBN_Fields_2.json and paste into OpenRefine\n",
    "\n",
    "Open a text filter for \"ISBN Type\", click on the number of choices to get the facet choices as TSV, paste into variable \"ISBN_Fields\" below, and run cell"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 597,
   "metadata": {},
   "outputs": [],
   "source": [
    "ISBN_Types = \"\"\"\n",
    "eISBN 10\t20\n",
    "eISBN 10 no 2\t3\n",
    "eISBN 10 no 3\t3\n",
    "eISBN 13\t20\n",
    "eISBN 13 no 2\t4\n",
    "eISBN 13 no 3\t3\n",
    "EPUB eISBN 10\t1\n",
    "EPUB eISBN 13\t1\n",
    "HB ISBN 10\t1\n",
    "HB ISBN 13\t3\n",
    "ISBN 10\t16\n",
    "ISBN 10 no 2\t2\n",
    "ISBN 13\t20\n",
    "ISBN 13 no 2\t4\n",
    "PB ISBN 10\t2\n",
    "PB ISBN 13\t2\n",
    "\"\"\""
   ]
  },
  {
   "source": [
    "Copy Pivot_Fields_and_Values.json and paste into OpenRefine"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 598,
   "metadata": {},
   "outputs": [],
   "source": [
    "ISBN_Types = ISBN_Types.split(\"\\n\")[1:-1] # The splice removes elements created by having the opening and closing quotes on their own lines\n",
    "ISBN_Fields = []\n",
    "for ISBN_Type in ISBN_Types:\n",
    "    ISBN_Type = ISBN_Type.rstrip(\"1234567890\")\n",
    "    ISBN_Type = ISBN_Type.rstrip(\"\\t\")\n",
    "    ISBN_Fields.append(ISBN_Type)\n",
    "\n",
    "with open('JSON_Output.txt', 'w') as For_OpenRefine:\n",
    "    For_OpenRefine.write(\"[\")\n",
    "    for ISBN_Type in ISBN_Fields:\n",
    "        Template_String = f\"\"\"\n",
    "            {{\n",
    "                \"op\": \"core/text-transform\",\n",
    "                \"engineConfig\": {{\n",
    "                \"facets\": [],\n",
    "                \"mode\": \"record-based\"\n",
    "                }},\n",
    "                \"columnName\": \"{ISBN_Type}\",\n",
    "                \"expression\": \"grel:row.record.cells[\\\\\"{ISBN_Type}\\\\\"].value[0]\",\n",
    "                \"onError\": \"keep-original\",\n",
    "                \"repeat\": false,\n",
    "                \"repeatCount\": 10,\n",
    "                \"description\": \"Fill up and down values in ``{ISBN_Type}``\"\n",
    "            }},\n",
    "            {{\n",
    "                \"op\": \"core/blank-down\",\n",
    "                \"engineConfig\": {{\n",
    "                \"facets\": [],\n",
    "                \"mode\": \"record-based\"\n",
    "                }},\n",
    "                \"columnName\": \"{ISBN_Type}\",\n",
    "                \"description\": \"Blank down cells in column ``{ISBN_Type}``\"\n",
    "            }}\n",
    "        \"\"\"\n",
    "        For_OpenRefine.write(Template_String)\n",
    "    For_OpenRefine.write(\"]\")"
   ]
  },
  {
   "source": [
    "Run all cells, then copy JSON_Output.txt and paste into OpenRefine\n",
    "\n",
    "Copy Remove_Blank_Rows_After_Pivot.json and paste into OpenRefine\n",
    "\n",
    "# Organize HOL\n",
    "\n",
    "> Start by loading Alpeh Sequential text file into OpenRefine with column widths 10,5,3\n",
    "\n",
    "Put the unique name of the OpenRefine project for the HOL records in the variable `HOL_Project_Name` and run the cell"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 599,
   "metadata": {},
   "outputs": [],
   "source": [
    "HOL_Project_Name = \"oso_hol_misc_2021 05 02 txt\""
   ]
  },
  {
   "source": [
    "Copy Organize_Aleph_Sequential_for_HOL.json and paste into OpenRefine\n",
    "\n",
    "Open a text filter for \"Fields\", click on the number of choices to get the facet choices as TSV, paste into variable `Number_of_TKRs` below, and run cell (if there aren't any TKRs, do this same procedure with `Number_of_TKRs` as an empty string)"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "source": [
    "Number_of_TKRs = \"\"\"\n",
    "\"\"\""
   ],
   "cell_type": "code",
   "metadata": {},
   "execution_count": 600,
   "outputs": []
  },
  {
   "source": [
    "Copy Pivot_Fields_and_Values.json and paste into OpenRefine"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 601,
   "metadata": {},
   "outputs": [],
   "source": [
    "Number_of_TKRs = Number_of_TKRs.split(\"\\n\")[1:-1] # The splice removes elements created by having the opening and closing quotes on their own lines\n",
    "TKR_Fields = []\n",
    "for TKR in Number_of_TKRs:\n",
    "    TKR = TKR.rstrip(\"1234567890\")\n",
    "    TKR = TKR.rstrip(\"\\t\")\n",
    "    TKR_Fields.append(TKR)\n",
    "\n",
    "with open('JSON_Output.txt', 'w') as For_OpenRefine:\n",
    "    For_OpenRefine.write(\"[\")\n",
    "    for TKR_Field in TKR_Fields:\n",
    "        Template_String = f\"\"\"\n",
    "            {{\n",
    "                \"op\": \"core/text-transform\",\n",
    "                \"engineConfig\": {{\n",
    "                \"facets\": [],\n",
    "                \"mode\": \"record-based\"\n",
    "                }},\n",
    "                \"columnName\": \"{TKR_Field}\",\n",
    "                \"expression\": \"grel:row.record.cells[\\\\\"{TKR_Field}\\\\\"].value[0]\",\n",
    "                \"onError\": \"keep-original\",\n",
    "                \"repeat\": false,\n",
    "                \"repeatCount\": 10,\n",
    "                \"description\": \"Fill up and down values in ``{TKR_Field}``\"\n",
    "            }},\n",
    "            {{\n",
    "                \"op\": \"core/blank-down\",\n",
    "                \"engineConfig\": {{\n",
    "                \"facets\": [],\n",
    "                \"mode\": \"record-based\"\n",
    "                }},\n",
    "                \"columnName\": \"{TKR_Field}\",\n",
    "                \"description\": \"Blank down cells in column ``{TKR_Field}``\"\n",
    "            }}\n",
    "        \"\"\"\n",
    "        For_OpenRefine.write(Template_String)\n",
    "    For_OpenRefine.write(\"]\")"
   ]
  },
  {
   "source": [
    "Run the cell above, then copy JSON_Output.txt and paste into OpenRefine\n",
    "\n",
    "**Need to determine what to do when multiple HOL for same BIB happen**\n",
    "\n",
    "Copy Organize_TKRs.json and paste into OpenRefine\n"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "source": [
    "## Add HOL data to BIB project\n",
    "Switch back to BIB project and set `i` to position of first identifier column\n",
    "\n",
    "Run all cells, then copy JSON_Output.txt and paste into OpenRefine"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 602,
   "metadata": {},
   "outputs": [],
   "source": [
    "i = 4\n",
    "\n",
    "with open('JSON_Output.txt', 'w') as For_OpenRefine:\n",
    "    Template_String = f\"\"\"\n",
    "        [\n",
    "            {{\n",
    "                \"op\": \"core/column-addition\",\n",
    "                \"engineConfig\": {{\n",
    "                    \"facets\": [],\n",
    "                    \"mode\": \"row-based\"\n",
    "                }},\n",
    "                \"baseColumnName\": \"SYS Number\",\n",
    "                \"expression\": \"grel:cell.cross(\\\\\"{HOL_Project_Name}\\\\\",\\\\\"BIB Number\\\\\").cells[\\\\\"HOL Sublibrary\\\\\"].value[0]\",\n",
    "                \"onError\": \"set-to-blank\",\n",
    "                \"newColumnName\": \"Sublibrary\",\n",
    "                \"columnInsertIndex\": {i},\n",
    "                \"description\": \"Create column ``Sublibrary`` with the sublibrary value from row with same BIB in HOL project\"\n",
    "            }},\n",
    "            {{\n",
    "                \"op\": \"core/column-addition\",\n",
    "                \"engineConfig\": {{\n",
    "                    \"facets\": [],\n",
    "                    \"mode\": \"row-based\"\n",
    "                }},\n",
    "                \"baseColumnName\": \"SYS Number\",\n",
    "                \"expression\": \"grel:cell.cross(\\\\\"{HOL_Project_Name}\\\\\",\\\\\"BIB Number\\\\\").cells[\\\\\"SYS Number\\\\\"].value[0]\",\n",
    "                \"onError\": \"set-to-blank\",\n",
    "                \"newColumnName\": \"HOL Number\",\n",
    "                \"columnInsertIndex\": {i+1},\n",
    "                \"description\": \"Create column ``HOL Number`` with the HOL number from row with same BIB in HOL project\"\n",
    "            }},\n",
    "            {{\n",
    "                \"op\": \"core/column-addition\",\n",
    "                \"engineConfig\": {{\n",
    "                    \"facets\": [],\n",
    "                    \"mode\": \"row-based\"\n",
    "                }},\n",
    "                \"baseColumnName\": \"SYS Number\",\n",
    "                \"expression\": \"grel:cell.cross(\\\\\"{HOL_Project_Name}\\\\\",\\\\\"BIB Number\\\\\").cells.Suppressed.value[0]\",\n",
    "                \"onError\": \"set-to-blank\",\n",
    "                \"newColumnName\": \"Suppressed\",\n",
    "                \"columnInsertIndex\": {i+2},\n",
    "                \"description\": \"Create column ``Suppressed`` with the value from column of the same name in the row with same BIB in HOL project\"\n",
    "            }},\n",
    "    \"\"\"\n",
    "    For_OpenRefine.write(Template_String)\n",
    "    for TKR_Field_Number in range(len(TKR_Fields)):\n",
    "        Template_String = f\"\"\"\n",
    "            {{\n",
    "                \"op\": \"core/column-addition\",\n",
    "                \"engineConfig\": {{\n",
    "                    \"facets\": [],\n",
    "                    \"mode\": \"row-based\"\n",
    "                }},\n",
    "                \"baseColumnName\": \"SYS Number\",\n",
    "                \"expression\": \"grel:cell.cross(\\\\\"{HOL_Project_Name}\\\\\",\\\\\"BIB Number\\\\\").cells[\\\\\"TKR {TKR_Field_Number+1}\\\\\"].value[0]\",\n",
    "                \"onError\": \"set-to-blank\",\n",
    "                \"newColumnName\": \"TKR {TKR_Field_Number+1}\",\n",
    "                \"columnInsertIndex\": {TKR_Field_Number+i},\n",
    "                \"description\": \"Create column ``TKR {TKR_Field_Number+1}`` with the value from the TKR column of the same number from row with same BIB in HOL project\"\n",
    "            }}\n",
    "        \"\"\"\n",
    "        For_OpenRefine.write(Template_String)\n",
    "    For_OpenRefine.write(\"]\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ]
}