{
 "metadata": {
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.1-final"
  },
  "orig_nbformat": 2,
  "kernelspec": {
   "name": "python381jvsc74a57bd0808c0b65fb29d89f35c9ec8e00426afb986d0b65f026dc2bfd8b25d992fc8a8f",
   "display_name": "Python 3.8.1 32-bit"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2,
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 325,
   "metadata": {},
   "outputs": [],
   "source": [
    "Identifier_and_Name = {\n",
    "    \"Au-PeEL\": \"Ebook Library\",\n",
    "    \"CaONFJC\": \"MyiLibrary\",\n",
    "    \"CaPaEBR\": \"Ebrary\",\n",
    "    \"DE-He213\": \"Springer-Verlag\",\n",
    "    \"MiAaPQ\": \"ProQuest\",\n",
    "    \"NhCcYBP\": \"YBP\",\n",
    "    \"OCoLC\": \"OCLC\",\n",
    "    \"SFPDA_MiAaPQ\": \"ProQuest\",\n",
    "    \"YBPUID\": \"YBP ID\",\n",
    "    \"MIL\": \"MyiLibrary\",\n",
    "    \"EBR\": \"Ebrary\",\n",
    "    \"EBL\": \"Ebook Library\",\n",
    "    \"EBC\": \"Ebook Central\",\n",
    "    \"CaBNVSL\": \"SIAM\",\n",
    "    \"CaBNvSL\": \"SIAM\",\n",
    "    \"DcWaAPA\": \"APA\",\n",
    "    \"DNLM\": \"US Med Library\",\n",
    "    \"FR-PaOEC\": \"OECD\",\n",
    "    \"IN-ChSCO\": \"Scope e-Knowedge Center\",\n",
    "    \"MiFhGG\": \"Gale\",\n",
    "    \"StDuBDS\": \"Bibliographic Data Services\",\n",
    "    \"UtOrBLW\": \"Backstage Library Works\",\n",
    "    \"VaAlASP\": \"Alexander Street Press\",\n",
    "    \"EBS\": \"EBSCO\",\n",
    "    \"FANhCcYBP\": \"YBP (FA)\",\n",
    "    \"UK-OxUP\": \"Oxford UP\",\n",
    "    \"no label\": \"Unlabeled\",\n",
    "}"
   ]
  },
  {
   "source": [
    "> Start by loading Alpeh Sequential text file into OpenRefine with column widths 10,6,2\n",
    "\n",
    "Put the unique name of the OpenRefine project for the BIB records in the variable `BIB_Project_Name` and run the cell"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 341,
   "metadata": {},
   "outputs": [],
   "source": [
    "BIB_Project_Name = \"wiley_bib_3 8 2021 txt\""
   ]
  },
  {
   "source": [
    "# Organize BIB Record\n",
    "\n",
    "## Organize MARC Fields and Subfields\n",
    "Copy Organize_Alpeh_Sequential_for_BIB.json and paste into OpenRefine"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "source": [
    "## Pivot Subfields into Columns\n",
    "Use a filter on \"No Field Number\" to select the following subfields, invert, then remove all matching rows:\n",
    "\n",
    "- 020$a\n",
    "- 020$q\n",
    "- 020$z\n",
    "- 024$2\n",
    "- 024$a\n",
    "- 035$a\n",
    "- 245$a\n",
    "- 245$b\n",
    "- 245$c\n",
    "- 245$n\n",
    "- 250$a\n",
    "- 264$b\n",
    "- 264$c\n",
    "- 710$a\n",
    "- 710$e\n",
    "- 776$i\n",
    "- 776$z\n",
    "- 856$3\n",
    "- 856$u\n",
    "- 856$z\n",
    "- 897$a\n",
    "- 897$e\n",
    "\n",
    "Open a text filter for \"Fields,\" click on the number of choices to get the facet choices as TSV, paste into variable \"Columns\" below, and run cell"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 342,
   "metadata": {},
   "outputs": [],
   "source": [
    "Columns = \"\"\"\n",
    "020$a\t274\n",
    "020$z\t2\n",
    "024$2\t390\n",
    "024$a\t539\n",
    "035$a\t3319\n",
    "245$a\t3427\n",
    "245$b\t892\n",
    "245$c\t1393\n",
    "245$n\t63\n",
    "250$a\t278\n",
    "264$b\t3039\n",
    "264$c\t2124\n",
    "776$i\t1314\n",
    "776$z\t1538\n",
    "856$3\t1031\n",
    "856$u\t1770\n",
    "856$z\t392\n",
    "Field #1 020$a\t1118\n",
    "Field #1 020$q\t467\n",
    "Field #1 020$z\t33\n",
    "Field #1 024$2\t26\n",
    "Field #1 024$a\t36\n",
    "Field #1 035$a\t108\n",
    "Field #1 264$b\t454\n",
    "Field #1 264$c\t299\n",
    "Field #1 776$i\t889\n",
    "Field #1 776$z\t83\n",
    "Field #1 856$3\t2\n",
    "Field #1 856$u\t1657\n",
    "Field #1 856$z\t1653\n",
    "Field #10 020$a\t73\n",
    "Field #10 020$q\t70\n",
    "Field #10 020$z\t82\n",
    "Field #10 856$u\t76\n",
    "Field #10 856$z\t76\n",
    "Field #11 020$a\t41\n",
    "Field #11 020$q\t29\n",
    "Field #11 020$z\t34\n",
    "Field #11 856$u\t55\n",
    "Field #11 856$z\t55\n",
    "Field #12 020$a\t31\n",
    "Field #12 020$q\t23\n",
    "Field #12 020$z\t27\n",
    "Field #12 856$u\t43\n",
    "Field #12 856$z\t43\n",
    "Field #13 020$a\t13\n",
    "Field #13 020$q\t17\n",
    "Field #13 020$z\t21\n",
    "Field #13 856$u\t33\n",
    "Field #13 856$z\t33\n",
    "Field #14 020$a\t6\n",
    "Field #14 020$q\t7\n",
    "Field #14 020$z\t11\n",
    "Field #14 856$u\t27\n",
    "Field #14 856$z\t27\n",
    "Field #15 020$a\t1\n",
    "Field #15 020$q\t3\n",
    "Field #15 020$z\t7\n",
    "Field #15 856$u\t21\n",
    "Field #15 856$z\t21\n",
    "Field #16 020$a\t1\n",
    "Field #16 020$q\t2\n",
    "Field #16 020$z\t4\n",
    "Field #16 856$u\t14\n",
    "Field #16 856$z\t14\n",
    "Field #17 020$z\t2\n",
    "Field #17 856$u\t10\n",
    "Field #17 856$z\t10\n",
    "Field #18 020$z\t2\n",
    "Field #18 856$u\t2\n",
    "Field #18 856$z\t2\n",
    "Field #19 020$z\t1\n",
    "Field #19 856$u\t2\n",
    "Field #19 856$z\t2\n",
    "Field #2 020$a\t1126\n",
    "Field #2 020$q\t466\n",
    "Field #2 020$z\t24\n",
    "Field #2 024$2\t9\n",
    "Field #2 024$a\t36\n",
    "Field #2 035$a\t108\n",
    "Field #2 264$b\t352\n",
    "Field #2 264$c\t70\n",
    "Field #2 776$i\t298\n",
    "Field #2 776$z\t88\n",
    "Field #2 856$3\t3\n",
    "Field #2 856$u\t1655\n",
    "Field #2 856$z\t1651\n",
    "Field #20 020$z\t1\n",
    "Field #20 856$u\t2\n",
    "Field #20 856$z\t2\n",
    "Field #21 020$z\t1\n",
    "Field #21 856$u\t1\n",
    "Field #21 856$z\t1\n",
    "Field #3 020$a\t837\n",
    "Field #3 020$q\t454\n",
    "Field #3 020$z\t135\n",
    "Field #3 035$a\t93\n",
    "Field #3 264$b\t77\n",
    "Field #3 264$c\t1\n",
    "Field #3 776$i\t64\n",
    "Field #3 776$z\t9\n",
    "Field #3 856$u\t1030\n",
    "Field #3 856$z\t1030\n",
    "Field #4 020$a\t824\n",
    "Field #4 020$q\t448\n",
    "Field #4 020$z\t114\n",
    "Field #4 035$a\t2\n",
    "Field #4 264$b\t15\n",
    "Field #4 776$i\t13\n",
    "Field #4 776$z\t2\n",
    "Field #4 856$u\t634\n",
    "Field #4 856$z\t634\n",
    "Field #5 020$a\t440\n",
    "Field #5 020$q\t321\n",
    "Field #5 020$z\t347\n",
    "Field #5 264$b\t4\n",
    "Field #5 776$i\t3\n",
    "Field #5 776$z\t1\n",
    "Field #5 856$u\t436\n",
    "Field #5 856$z\t436\n",
    "Field #6 020$a\t463\n",
    "Field #6 020$q\t302\n",
    "Field #6 020$z\t289\n",
    "Field #6 264$b\t2\n",
    "Field #6 856$u\t303\n",
    "Field #6 856$z\t303\n",
    "Field #7 020$a\t212\n",
    "Field #7 020$q\t207\n",
    "Field #7 020$z\t282\n",
    "Field #7 856$u\t203\n",
    "Field #7 856$z\t203\n",
    "Field #8 020$a\t202\n",
    "Field #8 020$q\t162\n",
    "Field #8 020$z\t193\n",
    "Field #8 856$u\t148\n",
    "Field #8 856$z\t148\n",
    "Field #9 020$a\t86\n",
    "Field #9 020$q\t102\n",
    "Field #9 020$z\t151\n",
    "Field #9 856$u\t111\n",
    "Field #9 856$z\t111\n",
    "\"\"\""
   ]
  },
  {
   "source": [
    "**Indicator columns deleted at this point--unsure how to handle/how or if to preserve beyond this point**\n",
    "\n",
    "Copy Pivot_Fields_and_Values.json and paste into OpenRefine"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 343,
   "metadata": {},
   "outputs": [],
   "source": [
    "Columns = Columns.split(\"\\n\")[1:-1] # The splice removes elements created by having the opening and closing quotes on their own lines\n",
    "Column_Names = []\n",
    "for Column in Columns:\n",
    "    Column = Column.rstrip(\"1234567890\")\n",
    "    Column = Column.rstrip(\"\\t\")\n",
    "    Column_Names.append(Column)\n",
    "\n",
    "with open('JSON_Output.txt', 'w') as For_OpenRefine:\n",
    "    For_OpenRefine.write(\"[\")\n",
    "    for Column in Column_Names:\n",
    "        Template_String = f\"\"\"\n",
    "            {{\n",
    "                \"op\": \"core/text-transform\",\n",
    "                \"engineConfig\": {{\n",
    "                \"facets\": [],\n",
    "                \"mode\": \"record-based\"\n",
    "                }},\n",
    "                \"columnName\": \"{Column}\",\n",
    "                \"expression\": \"grel:row.record.cells[\\\\\"{Column}\\\\\"].value[0]\",\n",
    "                \"onError\": \"keep-original\",\n",
    "                \"repeat\": false,\n",
    "                \"repeatCount\": 10,\n",
    "                \"description\": \"Fill up and down values in ``{Column}``\"\n",
    "            }},\n",
    "            {{\n",
    "                \"op\": \"core/blank-down\",\n",
    "                \"engineConfig\": {{\n",
    "                \"facets\": [],\n",
    "                \"mode\": \"record-based\"\n",
    "                }},\n",
    "                \"columnName\": \"{Column}\",\n",
    "                \"description\": \"Blank down cells in column ``{Column}``\"\n",
    "            }},\n",
    "        \"\"\"\n",
    "        For_OpenRefine.write(Template_String)\n",
    "    For_OpenRefine.write(\"]\")"
   ]
  },
  {
   "source": [
    "Run all cells, then copy JSON_Output.txt and paste into OpenRefine\n",
    "\n",
    "Copy Remove_Blank_Rows_After_Pivot.json and paste into OpenRefine"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 344,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def Column_Order_as_Letter(MARC_Tag):\n",
    "    if MARC_Tag == \"020$a\":\n",
    "        return \"A\"\n",
    "    elif MARC_Tag == \"020$z\":\n",
    "        return \"B\"\n",
    "    elif MARC_Tag == \"776$z\":\n",
    "        return \"C\"\n",
    "    elif MARC_Tag == \"020$q\":\n",
    "        return \"D\"\n",
    "    elif MARC_Tag == \"776$i\":\n",
    "        return \"E\"\n",
    "    elif MARC_Tag == \"024$a\":\n",
    "        return \"F\"\n",
    "    elif MARC_Tag == \"024$2\":\n",
    "        return \"G\"\n",
    "    elif MARC_Tag == \"035$a\":\n",
    "        return \"H\"\n",
    "    elif MARC_Tag == \"710$a\":\n",
    "        return \"I\"\n",
    "    elif MARC_Tag == \"710$e\":\n",
    "        return \"J\"\n",
    "    elif MARC_Tag == \"897$a\":\n",
    "        return \"K\"\n",
    "    elif MARC_Tag == \"897$e\":\n",
    "        return \"L\"\n",
    "    elif MARC_Tag == \"856$u\":\n",
    "        return \"M\"\n",
    "    elif MARC_Tag == \"856$z\":\n",
    "        return \"N\"\n",
    "    elif MARC_Tag == \"856$3\":\n",
    "        return \"O\"\n",
    "    elif MARC_Tag == \"264$c\":\n",
    "        return \"P\"\n",
    "    elif MARC_Tag == \"264$b\":\n",
    "        return \"Q\"\n",
    "    elif MARC_Tag == \"245$c\":\n",
    "        return \"R\"\n",
    "    elif MARC_Tag == \"250$a\":\n",
    "        return \"S\"\n",
    "    elif MARC_Tag == \"245$n\":\n",
    "        return \"T\"\n",
    "    elif MARC_Tag == \"245$b\":\n",
    "        return \"U\"\n",
    "    elif MARC_Tag == \"245$a\":\n",
    "        return \"V\"\n",
    "    # No \"else\" statement because if there's a problem here, it will require manual intervention\n",
    "\n",
    "Column_Order = {\n",
    "    \"A\": {},\n",
    "    \"B\": {},\n",
    "    \"C\": {},\n",
    "    \"D\": {},\n",
    "    \"E\": {},\n",
    "    \"F\": {},\n",
    "    \"G\": {},\n",
    "    \"H\": {},\n",
    "    \"I\": {},\n",
    "    \"J\": {},\n",
    "    \"K\": {},\n",
    "    \"L\": {},\n",
    "    \"M\": {},\n",
    "    \"N\": {},\n",
    "    \"O\": {},\n",
    "    \"P\": {},\n",
    "    \"Q\": {},\n",
    "    \"R\": {},\n",
    "    \"S\": {},\n",
    "    \"T\": {},\n",
    "    \"U\": {},\n",
    "    \"V\": {},\n",
    "}\n",
    "\n",
    "# Create nested dictionary for ordering columns\n",
    "for Column in Column_Names:\n",
    "    if \" \" in Column: # Has field number\n",
    "        Field_Number = int(Column.split(\" \")[1][1:])\n",
    "        Ordering_Letter = Column_Order_as_Letter(Column.split(\" \")[2])\n",
    "        Column_Order[Ordering_Letter][Field_Number] = Column\n",
    "    else:\n",
    "        Ordering_Letter = Column_Order_as_Letter(Column)\n",
    "        Column_Order[Ordering_Letter][0] = Column\n",
    "\n",
    "# Create markers to ensure that all first column in pivots exist\n",
    "if not Column_Order[\"Q\"].get(0): # If there's no column that's just \"264$b\"\n",
    "    Column_Order[\"Q\"][0] = \"264$b_marker\"\n",
    "if not Column_Order[\"P\"].get(0): # If there's no column that's jsut \"264$c\"\n",
    "    Column_Order[\"p\"][0] = \"264$c_marker\"\n",
    "if not Column_Order[\"O\"].get(0): # If there's no column that's just \"856$u\"\n",
    "    Column_Order[\"O\"][0] = \"856$u_marker\"\n",
    "if not Column_Order[\"H\"].get(0): # If there's no column that's just \"035$a\"\n",
    "    Column_Order[\"H\"][0] = \"035$a_marker\"\n",
    "if not Column_Order[\"A\"].get(0): # If there's no column that's just \"020$a\"\n",
    "    Column_Order[\"A\"][0] = \"020$a_marker\"\n",
    "\n",
    "# Sort by field order within tags\n",
    "for key, value in Column_Order.items():\n",
    "    value = dict(sorted(value.items()))\n",
    "    Column_Order[key] = value\n",
    "\n",
    "# Create list of column values and markers for columns needed for pivots in order\n",
    "Column_Order_Values = []\n",
    "for Outer_Value in Column_Order.values():\n",
    "    for Inner_Value in Outer_Value.values():\n",
    "        Column_Order_Values.append(Inner_Value)\n",
    "\n",
    "# Create dictionary for adding columns needed for pivots and list of existing columns for adding to JSON \n",
    "Pivot_Addition_Column_Indexes = {Column_Value[0:5]: Column_Order_Values.index(Column_Value)+2 for Column_Value in Column_Order_Values if \"_marker\" in Column_Value}\n",
    "Column_Order_Values = ['\"' + Column_Value + '\"' for Column_Value in Column_Order_Values if \"_marker\" not in Column_Value] #if \"_marker\" not in Column_Value\n",
    "Reordering_String = \",\\n\".join(Column_Order_Values)\n",
    "\n",
    "# Create final JSON for ordering columns\n",
    "with open('JSON_Output.txt', 'w') as For_OpenRefine:\n",
    "    Template_String = f\"\"\"\n",
    "        [\n",
    "            {{\n",
    "                \"op\": \"core/column-addition\",\n",
    "                \"description\": \"Create column ``Count``\",\n",
    "                \"engineConfig\": {{\n",
    "                    \"facets\": [],\n",
    "                    \"mode\": \"record-based\"\n",
    "                }},\n",
    "                \"newColumnName\": \"Count\",\n",
    "                \"columnInsertIndex\": 1,\n",
    "                \"baseColumnName\": \"SYS Number\",\n",
    "                \"expression\": \"grel:row.record.cells[\\\\\"SYS Number\\\\\"].value[0]+\\\\\"-\\\\\"+toString(row.index-row.record.fromRowIndex+1)\",\n",
    "                \"onError\": \"set-to-blank\"\n",
    "            }},\n",
    "            {{\n",
    "                \"op\": \"core/column-reorder\",\n",
    "                \"columnNames\": [\n",
    "                    \"SYS Number\",\n",
    "                    \"Count\",\n",
    "                    {Reordering_String}\n",
    "                ],\n",
    "                \"description\": \"Reorder columns\"\n",
    "            }}\n",
    "    \"\"\"\n",
    "    For_OpenRefine.write(Template_String)\n",
    "    for Column_Name, Column_Position in Pivot_Addition_Column_Indexes.items():\n",
    "        Template_String = f\"\"\"\n",
    "            {{\n",
    "                \"op\": \"core/column-addition\",\n",
    "                \"engineConfig\": {{\n",
    "                    \"facets\": [],\n",
    "                    \"mode\": \"record-based\"\n",
    "                }},\n",
    "                \"baseColumnName\": \"SYS Number\",\n",
    "                \"expression\": \"grel:null\",\n",
    "                \"onError\": \"set-to-blank\",\n",
    "                \"newColumnName\": \"{Column_Name}\",\n",
    "                \"columnInsertIndex\": {Column_Position},\n",
    "                \"description\": \"Create column ``{Column_Name}`` for pivoting\"\n",
    "            }}\n",
    "        \"\"\"\n",
    "        For_OpenRefine.write(Template_String)\n",
    "    For_OpenRefine.write(\"]\")"
   ]
  },
  {
   "source": [
    "Run all cells, then copy JSON_Output.txt and paste into OpenRefine\n",
    "\n",
    "Copy Organize_Rarely_Duplicated_Fields.json and paste into OpenRefine\n",
    "\n",
    "## Organize Publisher and Pub Date Fields\n",
    "\n",
    "**Multiple publisher fields handled by combining htem with `]|[` seperator; is there a better option?**\n",
    "\n",
    "Copy Organize_Publisher_Fields.json and paste into OpenRefine\n",
    "\n",
    "**PUB DATE ABLE TO HANDLE SAME DATE MULTIPLE TIMES--NEED TO FIGURE OUT STRATEGY FOR IF WE WANT TO PRESERVE BOTH DATES**\n",
    "\n",
    "Copy Organize_Pub_Date_Fields.json and paste into OpenRefine\n",
    "\n",
    "## Organize URLs\n",
    "\n",
    "Copy Organize_URL_Fields.json and paste into OpenRefine\n",
    "* If the row's value in \"Fields\" is null, the value in \"Values\" won't be retained through the pivot\n",
    "\n",
    "Open a text filter for \"Fields\", perform any clustering if appropriate, click on the number of choices to get the facet choices as TSV, paste into variable \"URL_Headers\" below, and run cell\n"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 330,
   "metadata": {},
   "outputs": [],
   "source": [
    "URL_Headers = \"\"\"\n",
    "University Press Scholarship Online\t20\n",
    "\"\"\""
   ]
  },
  {
   "source": [
    "Copy Pivot_Fields_and_Values.json and paste into OpenRefine\n",
    "\n",
    "Set \"i\" to the column number of column \"020$a\" and run cell"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 331,
   "metadata": {},
   "outputs": [],
   "source": [
    "URL_Headers = URL_Headers.split(\"\\n\")[1:-1] # The splice removes elements created by having the opening and closing quotes on their own lines\n",
    "Header_Names = []\n",
    "for Header in URL_Headers:\n",
    "    Header = Header.rstrip(\"1234567890\")\n",
    "    Header = Header.rstrip(\"\\t\")\n",
    "    Header_Names.append(Header)\n",
    "\n",
    "with open('JSON_Output.txt', 'w') as For_OpenRefine:\n",
    "    For_OpenRefine.write(\"[\")\n",
    "    i = 8\n",
    "    for Header in Header_Names:\n",
    "        Template_String = f\"\"\"\n",
    "            {{\n",
    "                \"op\": \"core/text-transform\",\n",
    "                \"engineConfig\": {{\n",
    "                \"facets\": [],\n",
    "                \"mode\": \"record-based\"\n",
    "                }},\n",
    "                \"columnName\": \"{Header}\",\n",
    "                \"expression\": \"grel:row.record.cells[\\\\\"{Header}\\\\\"].value[0]\",\n",
    "                \"onError\": \"keep-original\",\n",
    "                \"repeat\": false,\n",
    "                \"repeatCount\": 10,\n",
    "                \"description\": \"Fill up and down values in ``{Header}``\"\n",
    "            }},\n",
    "            {{\n",
    "                \"op\": \"core/blank-down\",\n",
    "                \"engineConfig\": {{\n",
    "                \"facets\": [],\n",
    "                \"mode\": \"record-based\"\n",
    "                }},\n",
    "                \"columnName\": \"{Header}\",\n",
    "                \"description\": \"Blank down cells in column ``{Header}``\"\n",
    "            }},\n",
    "            {{\n",
    "                \"op\": \"core/column-move\",\n",
    "                \"columnName\": \"{Header}\",\n",
    "                \"index\": {i},\n",
    "                \"description\": \"Move column ``{Header}`` to position {i}\"\n",
    "            }}\n",
    "        \"\"\"\n",
    "        For_OpenRefine.write(Template_String)\n",
    "        i += 1\n",
    "    For_OpenRefine.write(\"]\")"
   ]
  },
  {
   "source": [
    "Run all cells, then copy JSON_Output.txt and paste into OpenRefine\n",
    "\n",
    "Copy Remove_Blank_Rows_After_Pivot.json and paste into OpenRefine\n",
    "\n",
    "**897 and 710 fields not handled**\n",
    "\n",
    "## Organize Identifier Fields\n",
    "\n",
    "Copy Organize_Identifier_Fields.json and paste into OpenRefine\n",
    "\n",
    "Open a text filter for \"Fields\", click on the number of choices to get the facet choices as TSV, paste into variable \"Identifier_List\" below, and run cell"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 332,
   "metadata": {},
   "outputs": [],
   "source": [
    "Identifier_List = \"\"\"\n",
    "NhCcYBP\t15\n",
    "no label\t5\n",
    "YBPUID\t20\n",
    "\"\"\""
   ]
  },
  {
   "source": [
    "Copy Pivot_Fields_and_Values.json and paste into OpenRefine"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 333,
   "metadata": {},
   "outputs": [],
   "source": [
    "Identifier_List = Identifier_List.split(\"\\n\")[1:-1] # The splice removes elements created by having the opening and closing quotes on their own lines\n",
    "Identifiers = []\n",
    "for Identifier in Identifier_List:\n",
    "    Identifier = Identifier.rstrip(\"1234567890\")\n",
    "    Identifier = Identifier.rstrip(\"\\t\")\n",
    "    Identifiers.append(Identifier)\n",
    "\n",
    "Old_and_New_Headers = dict()\n",
    "for Identifier in Identifiers:\n",
    "    if Identifier_and_Name.get(Identifier) is None:\n",
    "        print(f\"{Identifier} doesn't have a value. Add one to the dictionary Identifier_and_Name at the top of the notebook and rerun all cells.\")\n",
    "        continue\n",
    "    Old_and_New_Headers[Identifier] = Identifier_and_Name.get(Identifier)\n",
    "\n",
    "Values_as_List = [l_org_code for l_org_code in Old_and_New_Headers.values()]\n",
    "Values_as_Set = set(Values_as_List)\n",
    "if len(Values_as_Set) < len(Values_as_List):\n",
    "    Duplicates_Check = dict()\n",
    "    for Set_Value in Values_as_Set:\n",
    "        Duplicates_Check[Set_Value] = 0\n",
    "        for List_Value in Values_as_List:\n",
    "            if Set_Value == List_Value:\n",
    "                Duplicates_Check[Set_Value] +=1\n",
    "\n",
    "    Repeated_Headers = []\n",
    "    for Key, Value in Duplicates_Check.items():\n",
    "        if Value > 1:\n",
    "            Repeated_Headers.append(Key)\n",
    "    print(\"The headers below were matched to multiple org codes in Identifier_List:\")\n",
    "    print(Repeated_Headers)\n"
   ]
  },
  {
   "source": [
    "Set \"i\" to the column number of column \"Author\""
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 334,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "with open('JSON_Output.txt', 'w') as For_OpenRefine:\n",
    "    For_OpenRefine.write(\"[\")\n",
    "    i = 5\n",
    "    for Key, Value in Old_and_New_Headers.items():\n",
    "        Template_String = f\"\"\"\n",
    "            {{\n",
    "                \"op\": \"core/column-addition\",\n",
    "                \"engineConfig\": {{\n",
    "                \"facets\": [],\n",
    "                \"mode\": \"row-based\"\n",
    "                }},\n",
    "                \"baseColumnName\": \"{Key}\",\n",
    "                \"expression\": \"grel:row.record.cells[\\\\\"{Key}\\\\\"].value[0]\",\n",
    "                \"onError\": \"set-to-blank\",\n",
    "                \"newColumnName\": \"{Value}\",\n",
    "                \"columnInsertIndex\": {i},\n",
    "                \"description\": \"Create column ``{Value}`` by filling up and down ``{Key}``\"\n",
    "            }},\n",
    "            {{\n",
    "                \"op\": \"core/blank-down\",\n",
    "                \"engineConfig\": {{\n",
    "                \"facets\": [],\n",
    "                \"mode\": \"record-based\"\n",
    "                }},\n",
    "                \"columnName\": \"{Value}\",\n",
    "                \"description\": \"Blank down cells in column ``{Value}``\"\n",
    "            }},\n",
    "            {{\n",
    "                \"op\": \"core/column-removal\",\n",
    "                \"columnName\": \"{Key}\",\n",
    "                \"description\": \"Remove column ``{Key}``\"\n",
    "            }}\n",
    "        \"\"\"\n",
    "        For_OpenRefine.write(Template_String)\n",
    "        i += 1\n",
    "    For_OpenRefine.write(\"]\")"
   ]
  },
  {
   "source": [
    "Run all cells, then copy JSON_Output.txt and paste into OpenRefine\n",
    "\n",
    "Copy Remove_Blank_Rows_After_Pivot.json and paste into OpenRefine\n",
    "\n",
    "## Organise ISBNs\n",
    "\n",
    "Copy Organize_ISBN_Fields_1.json and paste into OpenRefine\n",
    "\n",
    "Perform clustering on column \"ISBN Type\"\n",
    "\n",
    "Copy Organize_ISBN_Fields_2.json and paste into OpenRefine\n",
    "\n",
    "Open a text filter for \"ISBN Type\", click on the number of choices to get the facet choices as TSV, paste into variable \"ISBN_Fields\" below, and run cell"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 335,
   "metadata": {},
   "outputs": [],
   "source": [
    "ISBN_Types = \"\"\"\n",
    "eISBN 10\t20\n",
    "eISBN 10 no 2\t3\n",
    "eISBN 10 no 3\t3\n",
    "eISBN 13\t20\n",
    "eISBN 13 no 2\t4\n",
    "eISBN 13 no 3\t3\n",
    "EPUB eISBN 10\t1\n",
    "EPUB eISBN 13\t1\n",
    "HB ISBN 10\t1\n",
    "HB ISBN 13\t3\n",
    "ISBN 10\t16\n",
    "ISBN 10 no 2\t2\n",
    "ISBN 13\t20\n",
    "ISBN 13 no 2\t4\n",
    "PB ISBN 10\t2\n",
    "PB ISBN 13\t2\n",
    "\"\"\""
   ]
  },
  {
   "source": [
    "Copy Pivot_Fields_and_Values.json and paste into OpenRefine"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 336,
   "metadata": {},
   "outputs": [],
   "source": [
    "ISBN_Types = ISBN_Types.split(\"\\n\")[1:-1] # The splice removes elements created by having the opening and closing quotes on their own lines\n",
    "ISBN_Fields = []\n",
    "for ISBN_Type in ISBN_Types:\n",
    "    ISBN_Type = ISBN_Type.rstrip(\"1234567890\")\n",
    "    ISBN_Type = ISBN_Type.rstrip(\"\\t\")\n",
    "    ISBN_Fields.append(ISBN_Type)\n",
    "\n",
    "with open('JSON_Output.txt', 'w') as For_OpenRefine:\n",
    "    For_OpenRefine.write(\"[\")\n",
    "    for ISBN_Type in ISBN_Fields:\n",
    "        Template_String = f\"\"\"\n",
    "            {{\n",
    "                \"op\": \"core/text-transform\",\n",
    "                \"engineConfig\": {{\n",
    "                \"facets\": [],\n",
    "                \"mode\": \"record-based\"\n",
    "                }},\n",
    "                \"columnName\": \"{ISBN_Type}\",\n",
    "                \"expression\": \"grel:row.record.cells[\\\\\"{ISBN_Type}\\\\\"].value[0]\",\n",
    "                \"onError\": \"keep-original\",\n",
    "                \"repeat\": false,\n",
    "                \"repeatCount\": 10,\n",
    "                \"description\": \"Fill up and down values in ``{ISBN_Type}``\"\n",
    "            }},\n",
    "            {{\n",
    "                \"op\": \"core/blank-down\",\n",
    "                \"engineConfig\": {{\n",
    "                \"facets\": [],\n",
    "                \"mode\": \"record-based\"\n",
    "                }},\n",
    "                \"columnName\": \"{ISBN_Type}\",\n",
    "                \"description\": \"Blank down cells in column ``{ISBN_Type}``\"\n",
    "            }}\n",
    "        \"\"\"\n",
    "        For_OpenRefine.write(Template_String)\n",
    "    For_OpenRefine.write(\"]\")"
   ]
  },
  {
   "source": [
    "Run all cells, then copy JSON_Output.txt and paste into OpenRefine\n",
    "\n",
    "Copy Remove_Blank_Rows_After_Pivot.json and paste into OpenRefine\n",
    "\n",
    "# Organize HOL\n",
    "\n",
    "> Start by loading Alpeh Sequential text file into OpenRefine with column widths 10,5,3\n",
    "\n",
    "Put the unique name of the OpenRefine project for the HOL records in the variable `HOL_Project_Name` and run the cell"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 337,
   "metadata": {},
   "outputs": [],
   "source": [
    "HOL_Project_Name = \"oso_hol_misc_2021 05 02 txt\""
   ]
  },
  {
   "source": [
    "Copy Organize_Aleph_Sequential_for_HOL.json and paste into OpenRefine\n",
    "\n",
    "Open a text filter for \"Fields\", click on the number of choices to get the facet choices as TSV, paste into variable `Number_of_TKRs` below, and run cell (if there aren't any TKRs, do this same procedure with `Number_of_TKRs` as an empty string)"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "source": [
    "Number_of_TKRs = \"\"\"\n",
    "\"\"\""
   ],
   "cell_type": "code",
   "metadata": {},
   "execution_count": 338,
   "outputs": []
  },
  {
   "source": [
    "Copy Pivot_Fields_and_Values.json and paste into OpenRefine"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 339,
   "metadata": {},
   "outputs": [],
   "source": [
    "Number_of_TKRs = Number_of_TKRs.split(\"\\n\")[1:-1] # The splice removes elements created by having the opening and closing quotes on their own lines\n",
    "TKR_Fields = []\n",
    "for TKR in Number_of_TKRs:\n",
    "    TKR = TKR.rstrip(\"1234567890\")\n",
    "    TKR = TKR.rstrip(\"\\t\")\n",
    "    TKR_Fields.append(TKR)\n",
    "\n",
    "with open('JSON_Output.txt', 'w') as For_OpenRefine:\n",
    "    For_OpenRefine.write(\"[\")\n",
    "    for TKR_Field in TKR_Fields:\n",
    "        Template_String = f\"\"\"\n",
    "            {{\n",
    "                \"op\": \"core/text-transform\",\n",
    "                \"engineConfig\": {{\n",
    "                \"facets\": [],\n",
    "                \"mode\": \"record-based\"\n",
    "                }},\n",
    "                \"columnName\": \"{TKR_Field}\",\n",
    "                \"expression\": \"grel:row.record.cells[\\\\\"{TKR_Field}\\\\\"].value[0]\",\n",
    "                \"onError\": \"keep-original\",\n",
    "                \"repeat\": false,\n",
    "                \"repeatCount\": 10,\n",
    "                \"description\": \"Fill up and down values in ``{TKR_Field}``\"\n",
    "            }},\n",
    "            {{\n",
    "                \"op\": \"core/blank-down\",\n",
    "                \"engineConfig\": {{\n",
    "                \"facets\": [],\n",
    "                \"mode\": \"record-based\"\n",
    "                }},\n",
    "                \"columnName\": \"{TKR_Field}\",\n",
    "                \"description\": \"Blank down cells in column ``{TKR_Field}``\"\n",
    "            }}\n",
    "        \"\"\"\n",
    "        For_OpenRefine.write(Template_String)\n",
    "    For_OpenRefine.write(\"]\")"
   ]
  },
  {
   "source": [
    "Run the cell above, then copy JSON_Output.txt and paste into OpenRefine\n",
    "\n",
    "**Need to determine what to do when multiple HOL for same BIB happen**\n",
    "\n",
    "Copy Organize_TKRs.json and paste into OpenRefine\n"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "source": [
    "## Add HOL data to BIB project\n",
    "Switch back to BIB project and set `i` to position of first identifier column\n",
    "\n",
    "Run all cells, then copy JSON_Output.txt and paste into OpenRefine"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 340,
   "metadata": {},
   "outputs": [],
   "source": [
    "i = 4\n",
    "\n",
    "with open('JSON_Output.txt', 'w') as For_OpenRefine:\n",
    "    Template_String = f\"\"\"\n",
    "        [\n",
    "            {{\n",
    "                \"op\": \"core/column-addition\",\n",
    "                \"engineConfig\": {{\n",
    "                    \"facets\": [],\n",
    "                    \"mode\": \"row-based\"\n",
    "                }},\n",
    "                \"baseColumnName\": \"SYS Number\",\n",
    "                \"expression\": \"grel:cell.cross(\\\\\"{HOL_Project_Name}\\\\\",\\\\\"BIB Number\\\\\").cells[\\\\\"HOL Sublibrary\\\\\"].value[0]\",\n",
    "                \"onError\": \"set-to-blank\",\n",
    "                \"newColumnName\": \"Sublibrary\",\n",
    "                \"columnInsertIndex\": {i},\n",
    "                \"description\": \"Create column ``Sublibrary`` with the sublibrary value from row with same BIB in HOL project\"\n",
    "            }},\n",
    "            {{\n",
    "                \"op\": \"core/column-addition\",\n",
    "                \"engineConfig\": {{\n",
    "                    \"facets\": [],\n",
    "                    \"mode\": \"row-based\"\n",
    "                }},\n",
    "                \"baseColumnName\": \"SYS Number\",\n",
    "                \"expression\": \"grel:cell.cross(\\\\\"{HOL_Project_Name}\\\\\",\\\\\"BIB Number\\\\\").cells[\\\\\"SYS Number\\\\\"].value[0]\",\n",
    "                \"onError\": \"set-to-blank\",\n",
    "                \"newColumnName\": \"HOL Number\",\n",
    "                \"columnInsertIndex\": {i+1},\n",
    "                \"description\": \"Create column ``HOL Number`` with the HOL number from row with same BIB in HOL project\"\n",
    "            }},\n",
    "            {{\n",
    "                \"op\": \"core/column-addition\",\n",
    "                \"engineConfig\": {{\n",
    "                    \"facets\": [],\n",
    "                    \"mode\": \"row-based\"\n",
    "                }},\n",
    "                \"baseColumnName\": \"SYS Number\",\n",
    "                \"expression\": \"grel:cell.cross(\\\\\"{HOL_Project_Name}\\\\\",\\\\\"BIB Number\\\\\").cells.Suppressed.value[0]\",\n",
    "                \"onError\": \"set-to-blank\",\n",
    "                \"newColumnName\": \"Suppressed\",\n",
    "                \"columnInsertIndex\": {i+2},\n",
    "                \"description\": \"Create column ``Suppressed`` with the value from column of the same name in the row with same BIB in HOL project\"\n",
    "            }},\n",
    "    \"\"\"\n",
    "    For_OpenRefine.write(Template_String)\n",
    "    for TKR_Field_Number in range(len(TKR_Fields)):\n",
    "        Template_String = f\"\"\"\n",
    "            {{\n",
    "                \"op\": \"core/column-addition\",\n",
    "                \"engineConfig\": {{\n",
    "                    \"facets\": [],\n",
    "                    \"mode\": \"row-based\"\n",
    "                }},\n",
    "                \"baseColumnName\": \"SYS Number\",\n",
    "                \"expression\": \"grel:cell.cross(\\\\\"{HOL_Project_Name}\\\\\",\\\\\"BIB Number\\\\\").cells[\\\\\"TKR {TKR_Field_Number+1}\\\\\"].value[0]\",\n",
    "                \"onError\": \"set-to-blank\",\n",
    "                \"newColumnName\": \"TKR {TKR_Field_Number+1}\",\n",
    "                \"columnInsertIndex\": {TKR_Field_Number+i},\n",
    "                \"description\": \"Create column ``TKR {TKR_Field_Number+1}`` with the value from the TKR column of the same number from row with same BIB in HOL project\"\n",
    "            }}\n",
    "        \"\"\"\n",
    "        For_OpenRefine.write(Template_String)\n",
    "    For_OpenRefine.write(\"]\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ]
}