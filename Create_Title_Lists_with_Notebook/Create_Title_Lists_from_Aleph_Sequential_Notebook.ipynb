{
 "metadata": {
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.1"
  },
  "orig_nbformat": 2,
  "kernelspec": {
   "name": "python381jvsc74a57bd0808c0b65fb29d89f35c9ec8e00426afb986d0b65f026dc2bfd8b25d992fc8a8f",
   "display_name": "Python 3.8.1 32-bit"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2,
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "Identifier_and_Name = {\n",
    "    \"Au-PeEL\": \"Ebook Library\",\n",
    "    \"AU-PeEL\": \"Ebook Library\",\n",
    "    \"CaONFJC\": \"MyiLibrary\",\n",
    "    \"CaPaEBR\": \"Ebrary\",\n",
    "    \"DE-He213\": \"Springer-Verlag\",\n",
    "    \"MiAaPQ\": \"ProQuest\",\n",
    "    \"NhCcYBP\": \"YBP\",\n",
    "    \"OCoLC\": \"OCLC\",\n",
    "    \"SFPDA_MiAaPQ\": \"ProQuest\",\n",
    "    \"YBPUID\": \"YBP ID\",\n",
    "    \"MIL\": \"MyiLibrary\",\n",
    "    \"EBR\": \"Ebrary\",\n",
    "    \"ebrary\": \"Ebrary (full name)\",\n",
    "    \"EBZ\": \"EBSCO\",\n",
    "    \"EBL\": \"Ebook Library (unofficial)\",\n",
    "    \"EBC\": \"Ebook Central\",\n",
    "    \"CaBNVSL\": \"SIAM\",\n",
    "    \"CaBNvSL\": \"SIAM\",\n",
    "    \"DcWaAPA\": \"APA\",\n",
    "    \"DNLM\": \"US Med Library\",\n",
    "    \"FR-PaOEC\": \"OECD\",\n",
    "    \"IN-ChSCO\": \"Scope e-Knowedge Center\",\n",
    "    \"MiFhGG\": \"Gale\",\n",
    "    \"StDuBDS\": \"Bibliographic Data Services\",\n",
    "    \"UtOrBLW\": \"Backstage Library Works\",\n",
    "    \"VaAlASP\": \"Alexander Street Press\",\n",
    "    \"EBS\": \"EBSCO\",\n",
    "    \"FANhCcYBP\": \"YBP (FA)\",\n",
    "    \"UK-OxUP\": \"Oxford UP\",\n",
    "    \"no_label\": \"Unlabeled\",\n",
    "}"
   ]
  },
  {
   "source": [
    "> Start by loading Alpeh Sequential text file into OpenRefine with column widths 10,6,2\n",
    "\n",
    "Put the unique name of the OpenRefine project for the BIB records in the variable `BIB_Project_Name` and run the cell"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 588,
   "metadata": {},
   "outputs": [],
   "source": [
    "BIB_Project_Name = \"oso_bib_2021 05 10 txt\""
   ]
  },
  {
   "source": [
    "# Organize BIB Record\n",
    "\n",
    "## Organize MARC Fields and Subfields\n",
    "Copy Organize_Alpeh_Sequential_for_BIB.json and paste into OpenRefine"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "source": [
    "## Pivot Subfields into Columns\n",
    "Use a filter on \"No Field Number\" to select the following subfields, invert, then remove all matching rows:\n",
    "\n",
    "- 020$a\n",
    "- 020$q\n",
    "- 020$z\n",
    "- 024$2\n",
    "- 024$a\n",
    "- 035$a\n",
    "- 245$a\n",
    "- 245$b\n",
    "- 245$c\n",
    "- 245$n\n",
    "- 250$a\n",
    "- 264$b\n",
    "- 264$c\n",
    "- 710$a\n",
    "- 710$e\n",
    "- 776$i\n",
    "- 776$z\n",
    "- 856$3\n",
    "- 856$u\n",
    "- 856$z\n",
    "- 897$a\n",
    "- 897$e\n",
    "\n",
    "Open a text filter for \"Fields,\" click on the number of choices to get the facet choices as TSV, paste into variable \"Columns\" below, and run cell"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "Columns = \"\"\"\n",
    "020$a\t2365\n",
    "020$q\t10\n",
    "035$a\t4083\n",
    "245$a\t4388\n",
    "245$b\t2384\n",
    "245$c\t4345\n",
    "245$n\t118\n",
    "250$a\t687\n",
    "264$b\t4298\n",
    "264$c\t4296\n",
    "776$i\t4159\n",
    "776$z\t4481\n",
    "856$3\t3909\n",
    "856$u\t4386\n",
    "856$z\t261\n",
    "Field #1 020$a\t1737\n",
    "Field #1 020$q\t164\n",
    "Field #1 020$z\t1\n",
    "Field #1 035$a\t304\n",
    "Field #1 250$a\t1\n",
    "Field #1 264$b\t93\n",
    "Field #1 264$c\t93\n",
    "Field #1 776$i\t43\n",
    "Field #1 776$z\t45\n",
    "Field #1 856$3\t2\n",
    "Field #1 856$u\t2\n",
    "Field #10 020$q\t1\n",
    "Field #10 020$z\t3\n",
    "Field #11 020$z\t1\n",
    "Field #12 020$z\t1\n",
    "Field #2 020$a\t1736\n",
    "Field #2 020$q\t163\n",
    "Field #2 020$z\t2\n",
    "Field #2 035$a\t304\n",
    "Field #2 250$a\t1\n",
    "Field #2 264$b\t2\n",
    "Field #2 264$c\t92\n",
    "Field #2 776$i\t6\n",
    "Field #2 776$z\t88\n",
    "Field #2 856$3\t1\n",
    "Field #2 856$u\t2\n",
    "Field #3 020$a\t129\n",
    "Field #3 020$q\t127\n",
    "Field #3 020$z\t190\n",
    "Field #3 035$a\t291\n",
    "Field #3 776$z\t22\n",
    "Field #4 020$a\t128\n",
    "Field #4 020$q\t118\n",
    "Field #4 020$z\t178\n",
    "Field #5 020$a\t62\n",
    "Field #5 020$q\t84\n",
    "Field #5 020$z\t95\n",
    "Field #6 020$a\t60\n",
    "Field #6 020$q\t63\n",
    "Field #6 020$z\t72\n",
    "Field #7 020$a\t8\n",
    "Field #7 020$q\t57\n",
    "Field #7 020$z\t53\n",
    "Field #8 020$a\t5\n",
    "Field #8 020$q\t19\n",
    "Field #8 020$z\t29\n",
    "Field #9 020$q\t3\n",
    "Field #9 020$z\t5\n",
    "\"\"\""
   ]
  },
  {
   "source": [
    "**Indicator columns deleted at this point--unsure how to handle/how or if to preserve beyond this point**\n",
    "\n",
    "Copy Pivot_Fields_and_Values.json and paste into OpenRefine"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "Columns = Columns.split(\"\\n\")[1:-1] # The splice removes elements created by having the opening and closing quotes on their own lines\n",
    "Column_Names = []\n",
    "for Column in Columns:\n",
    "    Column = Column.rstrip(\"1234567890\")\n",
    "    Column = Column.rstrip(\"\\t\")\n",
    "    Column_Names.append(Column)\n",
    "\n",
    "with open('JSON_Output.txt', 'w') as For_OpenRefine:\n",
    "    For_OpenRefine.write(\"[\")\n",
    "    for Column in Column_Names:\n",
    "        Template_String = f\"\"\"\n",
    "            {{\n",
    "                \"op\": \"core/text-transform\",\n",
    "                \"engineConfig\": {{\n",
    "                \"facets\": [],\n",
    "                \"mode\": \"record-based\"\n",
    "                }},\n",
    "                \"columnName\": \"{Column}\",\n",
    "                \"expression\": \"grel:row.record.cells[\\\\\"{Column}\\\\\"].value[0]\",\n",
    "                \"onError\": \"keep-original\",\n",
    "                \"repeat\": false,\n",
    "                \"repeatCount\": 10,\n",
    "                \"description\": \"Fill up and down values in ``{Column}``\"\n",
    "            }},\n",
    "            {{\n",
    "                \"op\": \"core/blank-down\",\n",
    "                \"engineConfig\": {{\n",
    "                \"facets\": [],\n",
    "                \"mode\": \"record-based\"\n",
    "                }},\n",
    "                \"columnName\": \"{Column}\",\n",
    "                \"description\": \"Blank down cells in column ``{Column}``\"\n",
    "            }},\n",
    "        \"\"\"\n",
    "        For_OpenRefine.write(Template_String)\n",
    "    For_OpenRefine.write(\"]\")"
   ]
  },
  {
   "source": [
    "Run all cells, then copy JSON_Output.txt and paste into OpenRefine\n",
    "\n",
    "Copy Remove_Blank_Rows_After_Pivot.json and paste into OpenRefine"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def Column_Order_as_Letter(MARC_Tag):\n",
    "    if MARC_Tag == \"020$a\":\n",
    "        return \"A\"\n",
    "    elif MARC_Tag == \"020$z\":\n",
    "        return \"B\"\n",
    "    elif MARC_Tag == \"776$z\":\n",
    "        return \"C\"\n",
    "    elif MARC_Tag == \"020$q\":\n",
    "        return \"D\"\n",
    "    elif MARC_Tag == \"776$i\":\n",
    "        return \"E\"\n",
    "    elif MARC_Tag == \"024$a\":\n",
    "        return \"F\"\n",
    "    elif MARC_Tag == \"024$2\":\n",
    "        return \"G\"\n",
    "    elif MARC_Tag == \"035$a\":\n",
    "        return \"H\"\n",
    "    elif MARC_Tag == \"710$a\":\n",
    "        return \"I\"\n",
    "    elif MARC_Tag == \"710$e\":\n",
    "        return \"J\"\n",
    "    elif MARC_Tag == \"897$a\":\n",
    "        return \"K\"\n",
    "    elif MARC_Tag == \"897$e\":\n",
    "        return \"L\"\n",
    "    elif MARC_Tag == \"856$u\":\n",
    "        return \"M\"\n",
    "    elif MARC_Tag == \"856$z\":\n",
    "        return \"N\"\n",
    "    elif MARC_Tag == \"856$3\":\n",
    "        return \"O\"\n",
    "    elif MARC_Tag == \"264$c\":\n",
    "        return \"P\"\n",
    "    elif MARC_Tag == \"264$b\":\n",
    "        return \"Q\"\n",
    "    elif MARC_Tag == \"245$c\":\n",
    "        return \"R\"\n",
    "    elif MARC_Tag == \"250$a\":\n",
    "        return \"S\"\n",
    "    elif MARC_Tag == \"245$n\":\n",
    "        return \"T\"\n",
    "    elif MARC_Tag == \"245$b\":\n",
    "        return \"U\"\n",
    "    elif MARC_Tag == \"245$a\":\n",
    "        return \"V\"\n",
    "    # No \"else\" statement because if there's a problem here, it will require manual intervention\n",
    "\n",
    "Column_Order = {\n",
    "    \"A\": {},\n",
    "    \"B\": {},\n",
    "    \"C\": {},\n",
    "    \"D\": {},\n",
    "    \"E\": {},\n",
    "    \"F\": {},\n",
    "    \"G\": {},\n",
    "    \"H\": {},\n",
    "    \"I\": {},\n",
    "    \"J\": {},\n",
    "    \"K\": {},\n",
    "    \"L\": {},\n",
    "    \"M\": {},\n",
    "    \"N\": {},\n",
    "    \"O\": {},\n",
    "    \"P\": {},\n",
    "    \"Q\": {},\n",
    "    \"R\": {},\n",
    "    \"S\": {},\n",
    "    \"T\": {},\n",
    "    \"U\": {},\n",
    "    \"V\": {},\n",
    "}\n",
    "\n",
    "# Create nested dictionary for ordering columns\n",
    "for Column in Column_Names:\n",
    "    if \" \" in Column: # Has field number\n",
    "        Field_Number = int(Column.split(\" \")[1][1:])\n",
    "        Ordering_Letter = Column_Order_as_Letter(Column.split(\" \")[2])\n",
    "        Column_Order[Ordering_Letter][Field_Number] = Column\n",
    "    else:\n",
    "        Ordering_Letter = Column_Order_as_Letter(Column)\n",
    "        Column_Order[Ordering_Letter][0] = Column\n",
    "\n",
    "# Create markers to ensure that all first column in pivots exist\n",
    "if not Column_Order[\"Q\"].get(0): # If there's no column that's just \"264$b\"\n",
    "    Column_Order[\"Q\"][0] = \"264$b_marker\"\n",
    "if not Column_Order[\"P\"].get(0): # If there's no column that's jsut \"264$c\"\n",
    "    Column_Order[\"p\"][0] = \"264$c_marker\"\n",
    "if not Column_Order[\"O\"].get(0): # If there's no column that's just \"856$u\"\n",
    "    Column_Order[\"O\"][0] = \"856$u_marker\"\n",
    "if not Column_Order[\"H\"].get(0): # If there's no column that's just \"035$a\"\n",
    "    Column_Order[\"H\"][0] = \"035$a_marker\"\n",
    "if not Column_Order[\"A\"].get(0): # If there's no column that's just \"020$a\"\n",
    "    Column_Order[\"A\"][0] = \"020$a_marker\"\n",
    "\n",
    "# Sort by field order within tags\n",
    "for key, value in Column_Order.items():\n",
    "    value = dict(sorted(value.items()))\n",
    "    Column_Order[key] = value\n",
    "\n",
    "# Create list of column values and markers for columns needed for pivots in order\n",
    "Column_Order_Values = []\n",
    "for Outer_Value in Column_Order.values():\n",
    "    for Inner_Value in Outer_Value.values():\n",
    "        Column_Order_Values.append(Inner_Value)\n",
    "\n",
    "# Create dictionary for adding columns needed for pivots and list of existing columns for adding to JSON \n",
    "Pivot_Addition_Column_Indexes = {Column_Value[0:5]: Column_Order_Values.index(Column_Value)+2 for Column_Value in Column_Order_Values if \"_marker\" in Column_Value}\n",
    "Column_Order_Values = ['\"' + Column_Value + '\"' for Column_Value in Column_Order_Values if \"_marker\" not in Column_Value] #if \"_marker\" not in Column_Value\n",
    "Reordering_String = \",\\n\".join(Column_Order_Values)\n",
    "\n",
    "# Create final JSON for ordering columns\n",
    "with open('JSON_Output.txt', 'w') as For_OpenRefine:\n",
    "    Template_String = f\"\"\"\n",
    "        [\n",
    "            {{\n",
    "                \"op\": \"core/column-addition\",\n",
    "                \"description\": \"Create column ``Count``\",\n",
    "                \"engineConfig\": {{\n",
    "                    \"facets\": [],\n",
    "                    \"mode\": \"record-based\"\n",
    "                }},\n",
    "                \"newColumnName\": \"Count\",\n",
    "                \"columnInsertIndex\": 1,\n",
    "                \"baseColumnName\": \"SYS Number\",\n",
    "                \"expression\": \"grel:row.record.cells[\\\\\"SYS Number\\\\\"].value[0]+\\\\\"-\\\\\"+toString(row.index-row.record.fromRowIndex+1)\",\n",
    "                \"onError\": \"set-to-blank\"\n",
    "            }},\n",
    "            {{\n",
    "                \"op\": \"core/column-reorder\",\n",
    "                \"columnNames\": [\n",
    "                    \"SYS Number\",\n",
    "                    \"Count\",\n",
    "                    {Reordering_String}\n",
    "                ],\n",
    "                \"description\": \"Reorder columns\"\n",
    "            }}\n",
    "    \"\"\"\n",
    "    For_OpenRefine.write(Template_String)\n",
    "    for Column_Name, Column_Position in Pivot_Addition_Column_Indexes.items():\n",
    "        Template_String = f\"\"\"\n",
    "            {{\n",
    "                \"op\": \"core/column-addition\",\n",
    "                \"engineConfig\": {{\n",
    "                    \"facets\": [],\n",
    "                    \"mode\": \"record-based\"\n",
    "                }},\n",
    "                \"baseColumnName\": \"SYS Number\",\n",
    "                \"expression\": \"grel:null\",\n",
    "                \"onError\": \"set-to-blank\",\n",
    "                \"newColumnName\": \"{Column_Name}\",\n",
    "                \"columnInsertIndex\": {Column_Position},\n",
    "                \"description\": \"Create column ``{Column_Name}`` for pivoting\"\n",
    "            }}\n",
    "        \"\"\"\n",
    "        For_OpenRefine.write(Template_String)\n",
    "    For_OpenRefine.write(\"]\")"
   ]
  },
  {
   "source": [
    "Run all cells, then copy JSON_Output.txt and paste into OpenRefine\n",
    "\n",
    "Copy Organize_Rarely_Duplicated_Fields.json and paste into OpenRefine\n",
    "\n",
    "Confirm no columns with rarely duplicated information remain; if any do, move the information to the appropriate column and delete the original column\n",
    "\n",
    "Use text filters to standardize and clean up the contents of the \"Edition\" and \"Volume\" columns\n",
    "\n",
    "## Organize Publisher and Pub Date Fields\n",
    "\n",
    "**Multiple publisher fields handled by combining htem with `]|[` seperator; is there a better option?**\n",
    "\n",
    "Copy Organize_Publisher_Fields.json and paste into OpenRefine\n",
    "\n",
    "**PUB DATE ABLE TO HANDLE SAME DATE MULTIPLE TIMES--NEED TO FIGURE OUT STRATEGY FOR IF WE WANT TO PRESERVE BOTH DATES**\n",
    "\n",
    "Copy Organize_Pub_Date_Fields.json and paste into OpenRefine\n",
    "\n",
    "## Organize URLs\n",
    "\n",
    "Copy Organize_URL_Fields.json and paste into OpenRefine\n",
    "* If the row's value in \"Fields\" is null, the value in \"Values\" won't be retained through the pivot\n",
    "\n",
    "Open a text filter for \"Fields\", perform any clustering if appropriate, click on the number of choices to get the facet choices as TSV, paste into variable \"URL_Headers\" below, and run cell\n"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "URL_Headers = \"\"\"\n",
    "856$u\t477\n",
    "Ebook Central Science & Technology\t11\n",
    "EBSCOhost\t3\n",
    "Field #2 856$u\t1\n",
    "Knowledge Unlatched\t2\n",
    "Oxford Handbooks Online\t454\n",
    "Oxford Reference\t9\n",
    "Oxford Scholarship Online\t3412\n",
    "ProQuest Ebook Central\t1\n",
    "University Press Scholarship Online\t20\n",
    "\"\"\""
   ]
  },
  {
   "source": [
    "Copy Pivot_Fields_and_Values.json and paste into OpenRefine\n",
    "\n",
    "Set \"i\" to the column number of column \"020$a\" and run cell"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "URL_Headers = URL_Headers.split(\"\\n\")[1:-1] # The splice removes elements created by having the opening and closing quotes on their own lines\n",
    "Header_Names = []\n",
    "for Header in URL_Headers:\n",
    "    Header = Header.rstrip(\"1234567890\")\n",
    "    Header = Header.rstrip(\"\\t\")\n",
    "    Header_Names.append(Header)\n",
    "\n",
    "with open('JSON_Output.txt', 'w') as For_OpenRefine:\n",
    "    For_OpenRefine.write(\"[\")\n",
    "    i = 9\n",
    "    for Header in Header_Names:\n",
    "        Template_String = f\"\"\"\n",
    "            {{\n",
    "                \"op\": \"core/text-transform\",\n",
    "                \"engineConfig\": {{\n",
    "                \"facets\": [],\n",
    "                \"mode\": \"record-based\"\n",
    "                }},\n",
    "                \"columnName\": \"{Header}\",\n",
    "                \"expression\": \"grel:row.record.cells[\\\\\"{Header}\\\\\"].value[0]\",\n",
    "                \"onError\": \"keep-original\",\n",
    "                \"repeat\": false,\n",
    "                \"repeatCount\": 10,\n",
    "                \"description\": \"Fill up and down values in ``{Header}``\"\n",
    "            }},\n",
    "            {{\n",
    "                \"op\": \"core/blank-down\",\n",
    "                \"engineConfig\": {{\n",
    "                \"facets\": [],\n",
    "                \"mode\": \"record-based\"\n",
    "                }},\n",
    "                \"columnName\": \"{Header}\",\n",
    "                \"description\": \"Blank down cells in column ``{Header}``\"\n",
    "            }},\n",
    "            {{\n",
    "                \"op\": \"core/column-move\",\n",
    "                \"columnName\": \"{Header}\",\n",
    "                \"index\": {i},\n",
    "                \"description\": \"Move column ``{Header}`` to position {i}\"\n",
    "            }}\n",
    "        \"\"\"\n",
    "        For_OpenRefine.write(Template_String)\n",
    "        i += 1\n",
    "    For_OpenRefine.write(\"]\")"
   ]
  },
  {
   "source": [
    "Run all cells, then copy JSON_Output.txt and paste into OpenRefine\n",
    "\n",
    "Copy Remove_Blank_Rows_After_Pivot.json and paste into OpenRefine\n",
    "\n",
    "**897 and 710 fields not handled**\n",
    "\n",
    "## Organize 035$a Identifier Fields\n",
    "\n",
    "Copy Organize_035_Identifier_Fields.json and paste into OpenRefine\n",
    "\n",
    "Open a text filter for \"Fields\", evaluate any remaining options with asterists at the end, and remove the asterisk if the label is to remain or the lable if the value doesn't need to be retaiend\n",
    "\n",
    "In the text filter for \"Fields\", click on the number of choices to get the facet choices as TSV, paste into variable \"Identifier_List\" below, and run cell"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "Identifier_List = \"\"\"\n",
    "NhCcYBP\t291\n",
    "no_label\t12\n",
    "OCoLC\t30\n",
    "StDuBDS\t4013\n",
    "UK-OxUP\t32\n",
    "YBPUID\t313\n",
    "\"\"\""
   ]
  },
  {
   "source": [
    "Copy Pivot_Fields_and_Values.json and paste into OpenRefine"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "Identifier_List = Identifier_List.split(\"\\n\")[1:-1] # The splice removes elements created by having the opening and closing quotes on their own lines\n",
    "Identifiers = []\n",
    "for Identifier in Identifier_List:\n",
    "    Identifier = Identifier.rstrip(\"1234567890\")\n",
    "    Identifier = Identifier.rstrip(\"\\t\")\n",
    "    Identifiers.append(Identifier)\n",
    "\n",
    "Old_and_New_Headers = dict()\n",
    "for Identifier in Identifiers:\n",
    "    if len(Identifier.split(\" \")) == 1:\n",
    "        if Identifier_and_Name.get(Identifier) is None:\n",
    "            print(f\"{Identifier} doesn't have a value. Add one to the dictionary Identifier_and_Name at the top of the notebook and rerun all cells.\")\n",
    "            continue\n",
    "        Old_and_New_Headers[Identifier] = Identifier_and_Name.get(Identifier)\n",
    "    else: # This handles when multiple IDs with the same org code exist in a record\n",
    "        Repeated_Org_Code = Identifier.split(\" \")[0]\n",
    "        if Identifier_and_Name.get(Repeated_Org_Code) is None:\n",
    "            # No statement output because it would be repetitive\n",
    "            continue\n",
    "        Column_Name_Base = Identifier_and_Name.get(Repeated_Org_Code)\n",
    "        Old_and_New_Headers[Identifier] = Column_Name_Base + \" \" + Identifier.split(\" \")[1]\n",
    "\n",
    "Values_as_List = [Future_Column_Headers for Future_Column_Headers in Old_and_New_Headers.values()]\n",
    "Values_as_Set = set(Values_as_List)\n",
    "if len(Values_as_Set) < len(Values_as_List):\n",
    "    Duplicates_Check = dict()\n",
    "    for Set_Value in Values_as_Set:\n",
    "        Duplicates_Check[Set_Value] = 0\n",
    "        for List_Value in Values_as_List:\n",
    "            if Set_Value == List_Value:\n",
    "                Duplicates_Check[Set_Value] +=1\n",
    "\n",
    "    Repeated_Headers = []\n",
    "    for Key, Value in Duplicates_Check.items():\n",
    "        if Value > 1:\n",
    "            Repeated_Headers.append(Key)\n",
    "    print(\"The headers below were matched to multiple org codes in Identifier_List:\")\n",
    "    print(Repeated_Headers)\n"
   ]
  },
  {
   "source": [
    "Set `i` to the column number of column \"Author\""
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "with open('JSON_Output.txt', 'w') as For_OpenRefine:\n",
    "    For_OpenRefine.write(\"[\")\n",
    "    i = 8\n",
    "    for Key, Value in Old_and_New_Headers.items():\n",
    "        Template_String = f\"\"\"\n",
    "            {{\n",
    "                \"op\": \"core/column-addition\",\n",
    "                \"engineConfig\": {{\n",
    "                \"facets\": [],\n",
    "                \"mode\": \"row-based\"\n",
    "                }},\n",
    "                \"baseColumnName\": \"{Key}\",\n",
    "                \"expression\": \"grel:row.record.cells[\\\\\"{Key}\\\\\"].value[0]\",\n",
    "                \"onError\": \"set-to-blank\",\n",
    "                \"newColumnName\": \"{Value}\",\n",
    "                \"columnInsertIndex\": {i},\n",
    "                \"description\": \"Create column ``{Value}`` by filling up and down ``{Key}``\"\n",
    "            }},\n",
    "            {{\n",
    "                \"op\": \"core/blank-down\",\n",
    "                \"engineConfig\": {{\n",
    "                \"facets\": [],\n",
    "                \"mode\": \"record-based\"\n",
    "                }},\n",
    "                \"columnName\": \"{Value}\",\n",
    "                \"description\": \"Blank down cells in column ``{Value}``\"\n",
    "            }},\n",
    "            {{\n",
    "                \"op\": \"core/column-removal\",\n",
    "                \"columnName\": \"{Key}\",\n",
    "                \"description\": \"Remove column ``{Key}``\"\n",
    "            }}\n",
    "        \"\"\"\n",
    "        For_OpenRefine.write(Template_String)\n",
    "        i += 1\n",
    "    For_OpenRefine.write(\"]\")"
   ]
  },
  {
   "source": [
    "Run all cells, then copy JSON_Output.txt and paste into OpenRefine\n",
    "\n",
    "Copy Remove_Blank_Rows_After_Pivot.json and paste into OpenRefine\n",
    "\n",
    "## Organize Other Identifier ISBN_Fields\n",
    "\n",
    "Copy Organize_Other_Identifier_Fields.json and paste into OpenRefine\n",
    "\n",
    "Open a text filter for \"Fields\", change any field names if appropriate, click on the number of choices to get the facet choices as TSV, paste into variable \"Other_Identifiers_List\" below, and run cell"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 608,
   "metadata": {},
   "outputs": [],
   "source": [
    "Other_Identifiers_List = \"\"\"\n",
    "DOI\t425\n",
    "\"\"\""
   ]
  },
  {
   "source": [
    "Copy Pivot_Fields_and_Values.json and paste into OpenRefine\n",
    "\n",
    "Set `i` to the column number of the first URL column"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "source": [
    "Other_Identifiers_List = Other_Identifiers_List.split(\"\\n\")[1:-1] # The splice removes elements created by having the opening and closing quotes on their own lines\n",
    "Other_Identifiers = []\n",
    "for Other_Identifier in Other_Identifiers_List:\n",
    "    Other_Identifier = Other_Identifier.rstrip(\"1234567890\")\n",
    "    Other_Identifier = Other_Identifier.rstrip(\"\\t\")\n",
    "    Other_Identifiers.append(Other_Identifier)\n",
    "\n",
    "with open('JSON_Output.txt', 'w') as For_OpenRefine:\n",
    "    For_OpenRefine.write(\"[\")\n",
    "    i = 19\n",
    "    for Column_Name in Other_Identifiers:\n",
    "        Template_String = f\"\"\"\n",
    "            {{\n",
    "                \"op\": \"core/text-transform\",\n",
    "                \"engineConfig\": {{\n",
    "                \"facets\": [],\n",
    "                \"mode\": \"record-based\"\n",
    "                }},\n",
    "                \"columnName\": \"{Column_Name}\",\n",
    "                \"expression\": \"grel:row.record.cells[\\\\\"{Column_Name}\\\\\"].value[0]\",\n",
    "                \"onError\": \"keep-original\",\n",
    "                \"repeat\": false,\n",
    "                \"repeatCount\": 10,\n",
    "                \"description\": \"Fill up and down values in ``{Column_Name}``\"\n",
    "            }},\n",
    "            {{\n",
    "                \"op\": \"core/blank-down\",\n",
    "                \"engineConfig\": {{\n",
    "                \"facets\": [],\n",
    "                \"mode\": \"record-based\"\n",
    "                }},\n",
    "                \"columnName\": \"{Column_Name}\",\n",
    "                \"description\": \"Blank down cells in column ``{Column_Name}``\"\n",
    "            }},\n",
    "            {{\n",
    "                \"op\": \"core/column-move\",\n",
    "                \"columnName\": \"{Column_Name}\",\n",
    "                \"index\": {i},\n",
    "                \"description\": \"Move column ``{Column_Name}`` to position {i}\"\n",
    "            }}\n",
    "        \"\"\"\n",
    "        For_OpenRefine.write(Template_String)\n",
    "        i += 1\n",
    "    For_OpenRefine.write(\"]\")"
   ],
   "cell_type": "code",
   "metadata": {},
   "execution_count": 609,
   "outputs": []
  },
  {
   "source": [
    "Run all cells, then copy JSON_Output.txt and paste into OpenRefine\n",
    "\n",
    "Copy Remove_Blank_Rows_After_Pivot.json and paste into OpenRefine\n",
    "\n",
    "## Organise ISBNs\n",
    "\n",
    "Copy Organize_ISBN_Fields_1.json and paste into OpenRefine\n",
    "\n",
    "Perform clustering on column \"ISBN Type\"\n",
    "\n",
    "Copy Organize_ISBN_Fields_2.json and paste into OpenRefine\n",
    "\n",
    "Open a text filter for \"ISBN Type\", click on the number of choices to get the facet choices as TSV, paste into variable \"ISBN_Fields\" below, and run cell"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 612,
   "metadata": {},
   "outputs": [],
   "source": [
    "ISBN_Types = \"\"\"\n",
    "Blackwell Science eISBN 10\t1\n",
    "eISBN [set] 10\t2\n",
    "eISBN [set] 13\t2\n",
    "eISBN 10\t1411\n",
    "eISBN 10 no 2\t743\n",
    "eISBN 10 no 3\t293\n",
    "eISBN 10 no 4\t72\n",
    "eISBN 10 no 5\t18\n",
    "eISBN 10 no 6\t7\n",
    "eISBN 10 no 7\t2\n",
    "eISBN 13\t1122\n",
    "eISBN 13 no 2\t753\n",
    "eISBN 13 no 3\t294\n",
    "eISBN 13 no 4\t73\n",
    "eISBN 13 no 5\t17\n",
    "eISBN 13 no 6\t6\n",
    "eISBN 13 no 7\t2\n",
    "EPUB eISBN 10\t105\n",
    "EPUB eISBN 13\t112\n",
    "HB ISBN [set] 13\t1\n",
    "HB ISBN 10\t96\n",
    "HB ISBN 10 no 2\t1\n",
    "HB ISBN 10 no 3\t1\n",
    "HB ISBN 13\t170\n",
    "HB ISBN 13 no 2\t1\n",
    "HB ISBN 13 no 3\t1\n",
    "ISBN [set] 10\t3\n",
    "ISBN [set] 13\t3\n",
    "ISBN [vol. 1] 10\t1\n",
    "ISBN [vol. 1] 13\t1\n",
    "ISBN [vol. 2] 10\t1\n",
    "ISBN [vol. 2] 13\t1\n",
    "ISBN [vol. 3] 10\t2\n",
    "ISBN [vol. 3] 13\t2\n",
    "ISBN [vol. 4] 10\t1\n",
    "ISBN [vol. 4] 13\t1\n",
    "ISBN [vol. 5] 10\t1\n",
    "ISBN [vol. 5] 13\t1\n",
    "ISBN 10\t1023\n",
    "ISBN 10 no 2\t100\n",
    "ISBN 10 no 3\t22\n",
    "ISBN 10 no 4\t4\n",
    "ISBN 10 no 5\t1\n",
    "ISBN 10 no 6\t1\n",
    "ISBN 13\t955\n",
    "ISBN 13 no 2\t174\n",
    "ISBN 13 no 3\t43\n",
    "ISBN 13 no 4\t9\n",
    "ISBN 13 no 5\t3\n",
    "ISBN 13 no 6\t2\n",
    "Knovel eISBN 10\t1\n",
    "Knovel eISBN 13\t1\n",
    "Mobi eISBN 10\t51\n",
    "Mobi eISBN 13\t56\n",
    "MyiLibrary eISBN 10\t34\n",
    "MyiLibrary eISBN 13\t34\n",
    "PB ISBN 10\t84\n",
    "PB ISBN 13\t94\n",
    "PDF eISBN 10\t101\n",
    "PDF eISBN 13\t102\n",
    "Wiley eISBN 10\t2\n",
    "Wiley eISBN 13\t2\n",
    "\"\"\""
   ]
  },
  {
   "source": [
    "Copy Pivot_Fields_and_Values.json and paste into OpenRefine"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 613,
   "metadata": {},
   "outputs": [],
   "source": [
    "ISBN_Types = ISBN_Types.split(\"\\n\")[1:-1] # The splice removes elements created by having the opening and closing quotes on their own lines\n",
    "ISBN_Fields = []\n",
    "for ISBN_Type in ISBN_Types:\n",
    "    ISBN_Type = ISBN_Type.rstrip(\"1234567890\")\n",
    "    ISBN_Type = ISBN_Type.rstrip(\"\\t\")\n",
    "    ISBN_Fields.append(ISBN_Type)\n",
    "\n",
    "with open('JSON_Output.txt', 'w') as For_OpenRefine:\n",
    "    For_OpenRefine.write(\"[\")\n",
    "    for ISBN_Type in ISBN_Fields:\n",
    "        Template_String = f\"\"\"\n",
    "            {{\n",
    "                \"op\": \"core/text-transform\",\n",
    "                \"engineConfig\": {{\n",
    "                \"facets\": [],\n",
    "                \"mode\": \"record-based\"\n",
    "                }},\n",
    "                \"columnName\": \"{ISBN_Type}\",\n",
    "                \"expression\": \"grel:row.record.cells[\\\\\"{ISBN_Type}\\\\\"].value[0]\",\n",
    "                \"onError\": \"keep-original\",\n",
    "                \"repeat\": false,\n",
    "                \"repeatCount\": 10,\n",
    "                \"description\": \"Fill up and down values in ``{ISBN_Type}``\"\n",
    "            }},\n",
    "            {{\n",
    "                \"op\": \"core/blank-down\",\n",
    "                \"engineConfig\": {{\n",
    "                \"facets\": [],\n",
    "                \"mode\": \"record-based\"\n",
    "                }},\n",
    "                \"columnName\": \"{ISBN_Type}\",\n",
    "                \"description\": \"Blank down cells in column ``{ISBN_Type}``\"\n",
    "            }}\n",
    "        \"\"\"\n",
    "        For_OpenRefine.write(Template_String)\n",
    "    For_OpenRefine.write(\"]\")"
   ]
  },
  {
   "source": [
    "Run all cells, then copy JSON_Output.txt and paste into OpenRefine\n",
    "\n",
    "Copy Remove_Blank_Rows_After_Pivot.json and paste into OpenRefine\n",
    "\n",
    "# Organize HOL\n",
    "\n",
    "> Start by loading Alpeh Sequential text file into OpenRefine with column widths 10,5,3\n",
    "\n",
    "Put the unique name of the OpenRefine project for the HOL records in the variable `HOL_Project_Name` and run the cell"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 614,
   "metadata": {},
   "outputs": [],
   "source": [
    "HOL_Project_Name = \"wiley_hol_3 8 2021 txt\""
   ]
  },
  {
   "source": [
    "Copy Organize_Aleph_Sequential_for_HOL.json and paste into OpenRefine\n",
    "\n",
    "Open a text filter for \"Fields\", click on the number of choices to get the facet choices as TSV, paste into variable `Number_of_TKRs` below, and run cell (if there aren't any TKRs, do this same procedure with `Number_of_TKRs` as an empty string)"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "source": [
    "Number_of_TKRs = \"\"\"\n",
    "TKR 1\t3381\n",
    "TKR 10\t1336\n",
    "TKR 11\t1147\n",
    "TKR 12\t1091\n",
    "TKR 13\t623\n",
    "TKR 14\t527\n",
    "TKR 15\t341\n",
    "TKR 16\t269\n",
    "TKR 17\t199\n",
    "TKR 18\t141\n",
    "TKR 19\t97\n",
    "TKR 2\t1998\n",
    "TKR 20\t75\n",
    "TKR 21\t54\n",
    "TKR 22\t46\n",
    "TKR 23\t35\n",
    "TKR 24\t24\n",
    "TKR 25\t17\n",
    "TKR 26\t11\n",
    "TKR 27\t7\n",
    "TKR 28\t6\n",
    "TKR 29\t1\n",
    "TKR 3\t1923\n",
    "TKR 4\t1904\n",
    "TKR 5\t1854\n",
    "TKR 6\t1844\n",
    "TKR 7\t1817\n",
    "TKR 8\t1792\n",
    "TKR 9\t1377\n",
    "\"\"\""
   ],
   "cell_type": "code",
   "metadata": {},
   "execution_count": 615,
   "outputs": []
  },
  {
   "source": [
    "Copy Pivot_Fields_and_Values.json and paste into OpenRefine"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 616,
   "metadata": {},
   "outputs": [],
   "source": [
    "Number_of_TKRs = Number_of_TKRs.split(\"\\n\")[1:-1] # The splice removes elements created by having the opening and closing quotes on their own lines\n",
    "TKR_Fields = []\n",
    "for TKR in Number_of_TKRs:\n",
    "    TKR = TKR.rstrip(\"1234567890\")\n",
    "    TKR = TKR.rstrip(\"\\t\")\n",
    "    TKR_Fields.append(TKR)\n",
    "\n",
    "with open('JSON_Output.txt', 'w') as For_OpenRefine:\n",
    "    For_OpenRefine.write(\"[\")\n",
    "    for TKR_Field in TKR_Fields:\n",
    "        Template_String = f\"\"\"\n",
    "            {{\n",
    "                \"op\": \"core/text-transform\",\n",
    "                \"engineConfig\": {{\n",
    "                \"facets\": [],\n",
    "                \"mode\": \"record-based\"\n",
    "                }},\n",
    "                \"columnName\": \"{TKR_Field}\",\n",
    "                \"expression\": \"grel:row.record.cells[\\\\\"{TKR_Field}\\\\\"].value[0]\",\n",
    "                \"onError\": \"keep-original\",\n",
    "                \"repeat\": false,\n",
    "                \"repeatCount\": 10,\n",
    "                \"description\": \"Fill up and down values in ``{TKR_Field}``\"\n",
    "            }},\n",
    "            {{\n",
    "                \"op\": \"core/blank-down\",\n",
    "                \"engineConfig\": {{\n",
    "                \"facets\": [],\n",
    "                \"mode\": \"record-based\"\n",
    "                }},\n",
    "                \"columnName\": \"{TKR_Field}\",\n",
    "                \"description\": \"Blank down cells in column ``{TKR_Field}``\"\n",
    "            }}\n",
    "        \"\"\"\n",
    "        For_OpenRefine.write(Template_String)\n",
    "    For_OpenRefine.write(\"]\")"
   ]
  },
  {
   "source": [
    "Run the cell above, then copy JSON_Output.txt and paste into OpenRefine\n",
    "\n",
    "Copy Organize_TKRs.json and paste into OpenRefine\n"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "source": [
    "## Add HOL data to BIB project\n",
    "Switch back to BIB project and set `i` to position of first identifier column\n",
    "\n",
    "Run all cells, then copy JSON_Output.txt and paste into OpenRefine"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 625,
   "metadata": {},
   "outputs": [],
   "source": [
    "i = 8\n",
    "\n",
    "with open('JSON_Output.txt', 'w') as For_OpenRefine:\n",
    "    Template_String = f\"\"\"\n",
    "        [\n",
    "            {{\n",
    "                \"op\": \"core/column-addition\",\n",
    "                \"engineConfig\": {{\n",
    "                    \"facets\": [],\n",
    "                    \"mode\": \"record-based\"\n",
    "                }},\n",
    "                \"baseColumnName\": \"SYS Number\",\n",
    "                \"expression\": \"grel:cell.cross(\\\\\"{HOL_Project_Name}\\\\\",\\\\\"BIB Number\\\\\").cells[\\\\\"SYS Number\\\\\"].value.join(\\\\\"]|[\\\\\")\",\n",
    "                \"onError\": \"set-to-blank\",\n",
    "                \"newColumnName\": \"HOL Number\",\n",
    "                \"columnInsertIndex\": {i},\n",
    "                \"description\": \"Create column ``HOL Number`` with all the HOL numbers for the BIB seperated by `]|[`\"\n",
    "            }},\n",
    "            {{\n",
    "                \"op\": \"core/multivalued-cell-split\",\n",
    "                \"columnName\": \"HOL Number\",\n",
    "                \"keyColumnName\": \"SYS Number\",\n",
    "                \"mode\": \"separator\",\n",
    "                \"separator\": \"]|[\",\n",
    "                \"regex\": false,\n",
    "                \"description\": \"Split values in column ``HOL Numbers`` into new rows at `]|[`\"\n",
    "            }},\n",
    "            {{\n",
    "                \"op\": \"core/column-addition\",\n",
    "                \"engineConfig\": {{\n",
    "                    \"facets\": [],\n",
    "                    \"mode\": \"row-based\"\n",
    "                }},\n",
    "                \"baseColumnName\": \"HOL Number\",\n",
    "                \"expression\": \"grel:cell.cross(\\\\\"{HOL_Project_Name}\\\\\",\\\\\"SYS Number\\\\\").cells[\\\\\"HOL Sublibrary\\\\\"].value[0]\",\n",
    "                \"onError\": \"set-to-blank\",\n",
    "                \"newColumnName\": \"Sublibrary\",\n",
    "                \"columnInsertIndex\": {i+1},\n",
    "                \"description\": \"Create column ``Sublibrary`` with the sublibrary value from row with same BIB in HOL project\"\n",
    "            }},\n",
    "            {{\n",
    "                \"op\": \"core/column-addition\",\n",
    "                \"engineConfig\": {{\n",
    "                    \"facets\": [],\n",
    "                    \"mode\": \"row-based\"\n",
    "                }},\n",
    "                \"baseColumnName\": \"HOL Number\",\n",
    "                \"expression\": \"grel:cell.cross(\\\\\"{HOL_Project_Name}\\\\\",\\\\\"SYS Number\\\\\").cells.Suppressed.value[0]\",\n",
    "                \"onError\": \"set-to-blank\",\n",
    "                \"newColumnName\": \"Suppressed\",\n",
    "                \"columnInsertIndex\": {i+2},\n",
    "                \"description\": \"Create column ``Suppressed`` with the value from column of the same name in the row with same BIB in HOL project\"\n",
    "            }},\n",
    "    \"\"\"\n",
    "    For_OpenRefine.write(Template_String)\n",
    "    for TKR_Field_Number in range(len(TKR_Fields)):\n",
    "        Template_String = f\"\"\"\n",
    "            {{\n",
    "                \"op\": \"core/column-addition\",\n",
    "                \"engineConfig\": {{\n",
    "                    \"facets\": [],\n",
    "                    \"mode\": \"row-based\"\n",
    "                }},\n",
    "                \"baseColumnName\": \"SYS Number\",\n",
    "                \"expression\": \"grel:cell.cross(\\\\\"{HOL_Project_Name}\\\\\",\\\\\"BIB Number\\\\\").cells[\\\\\"TKR {TKR_Field_Number+1}\\\\\"].value[0]\",\n",
    "                \"onError\": \"set-to-blank\",\n",
    "                \"newColumnName\": \"TKR {TKR_Field_Number+1}\",\n",
    "                \"columnInsertIndex\": {i+TKR_Field_Number+3},\n",
    "                \"description\": \"Create column ``TKR {TKR_Field_Number+1}`` with the value from the TKR column of the same number from row with same BIB in HOL project\"\n",
    "            }}\n",
    "        \"\"\"\n",
    "        For_OpenRefine.write(Template_String)\n",
    "    For_OpenRefine.write(\"]\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ]
}